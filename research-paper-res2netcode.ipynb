{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n    add, multiply\nfrom keras.layers import concatenate, core, Dropout\nfrom keras.models import Model\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom keras.layers.core import Lambda\nimport keras.backend as K\n\n\n\n\ndef up_and_concate(down_layer, layer, data_format='channels_first'):\n    if data_format == 'channels_first':\n        in_channel = down_layer.get_shape().as_list()[1]\n    else:\n        in_channel = down_layer.get_shape().as_list()[3]\n\n    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n\n    if data_format == 'channels_first':\n        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n    else:\n        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n\n    concate = my_concat([up, layer])\n\n    return concate\n\n\ndef attention_up_and_concate(down_layer, layer, data_format='channels_first'):\n    if data_format == 'channels_first':\n        in_channel = down_layer.get_shape().as_list()[1]\n    else:\n        in_channel = down_layer.get_shape().as_list()[3]\n\n    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n\n    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n\n    if data_format == 'channels_first':\n        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n    else:\n        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n\n    concate = my_concat([up, layer])\n    return concate\n\n\ndef attention_block_2d(x, g, inter_channel, data_format='channels_first'):\n    # theta_x(?,g_height,g_width,inter_channel)\n\n    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n\n    # phi_g(?,g_height,g_width,inter_channel)\n\n    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n\n    # f(?,g_height,g_width,inter_channel)\n\n    f = Activation('relu')(add([theta_x, phi_g]))\n\n    # psi_f(?,g_height,g_width,1)\n\n    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n\n    rate = Activation('sigmoid')(psi_f)\n\n    # rate(?,x_height,x_width)\n\n    # att_x(?,x_height,x_width,x_channel)\n\n    att_x = multiply([x, rate])\n\n    return att_x\n\n\ndef res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n\n              padding='same', data_format='channels_first'):\n    if data_format == 'channels_first':\n        input_n_filters = input_layer.get_shape().as_list()[1]\n    else:\n        input_n_filters = input_layer.get_shape().as_list()[3]\n\n    layer = input_layer\n    for i in range(2):\n        layer = Conv2D(out_n_filters // 4, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n        if batch_normalization:\n            layer = BatchNormalization()(layer)\n        layer = Activation('relu')(layer)\n        layer = Conv2D(out_n_filters // 4, kernel_size, strides=stride, padding=padding, data_format=data_format)(layer)\n        layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n\n    if out_n_filters != input_n_filters:\n        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n            input_layer)\n    else:\n        skip_layer = input_layer\n    out_layer = add([layer, skip_layer])\n    return out_layer\n\n\n# Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\ndef rec_res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n\n                  padding='same', data_format='channels_first'):\n    if data_format == 'channels_first':\n        input_n_filters = input_layer.get_shape().as_list()[1]\n    else:\n        input_n_filters = input_layer.get_shape().as_list()[3]\n\n    if out_n_filters != input_n_filters:\n        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n            input_layer)\n    else:\n        skip_layer = input_layer\n\n    layer = skip_layer\n    for j in range(2):\n\n        for i in range(2):\n            if i == 0:\n\n                layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n                    layer)\n                if batch_normalization:\n                    layer1 = BatchNormalization()(layer1)\n                layer1 = Activation('relu')(layer1)\n            layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n                add([layer1, layer]))\n            if batch_normalization:\n                layer1 = BatchNormalization()(layer1)\n            layer1 = Activation('relu')(layer1)\n        layer = layer1\n\n    out_layer = add([layer, skip_layer])\n    return out_layer\n\n########################################################################################################\n# Define the neural network\ndef unet(img_w, img_h, n_label, data_format='channels_first'):\n    inputs = Input((3, img_w, img_h))\n    x = inputs\n    depth = 4\n    features = 64\n    skips = []\n    for i in range(depth):\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        x = Dropout(0.2)(x)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        skips.append(x)\n        x = MaxPooling2D((2, 2), data_format= data_format)(x)\n        features = features * 2\n\n    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n    x = Dropout(0.2)(x)\n    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n\n    for i in reversed(range(depth)):\n        features = features // 2\n        # attention_up_and_concate(x,[skips[i])\n        x = UpSampling2D(size=(2, 2), data_format=data_format)(x)\n        x = concatenate([skips[i], x], axis=1)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        x = Dropout(0.2)(x)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n\n    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n    conv7 = core.Activation('sigmoid')(conv6)\n    model = Model(inputs=inputs, outputs=conv7)\n\n    #model.compile(optimizer=Adam(lr=1e-5), loss=[focal_loss()], metrics=['accuracy', dice_coef])\n    return model\n\n\n########################################################################################################\n#Attention U-Net\ndef att_unet(img_w, img_h, n_label, data_format='channels_first'):\n    inputs = Input((3, img_w, img_h))\n    x = inputs\n    depth = 4\n    features = 64\n    skips = []\n    for i in range(depth):\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        x = Dropout(0.2)(x)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        skips.append(x)\n        x = MaxPooling2D((2, 2), data_format='channels_first')(x)\n        features = features * 2\n\n    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n    x = Dropout(0.2)(x)\n    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n\n    for i in reversed(range(depth)):\n        features = features // 2\n        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        x = Dropout(0.2)(x)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n\n    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n    conv7 = core.Activation('sigmoid')(conv6)\n    model = Model(inputs=inputs, outputs=conv7)\n\n    #model.compile(optimizer=Adam(lr=1e-5), loss=[focal_loss()], metrics=['accuracy', dice_coef])\n    return model\n\n\n########################################################################################################\n#Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\ndef r2_unet(img_w, img_h, n_label, data_format='channels_first'):\n    inputs = Input((3, img_w, img_h))\n    x = inputs\n    depth = 4\n    features = 64\n    skips = []\n    for i in range(depth):\n        x = rec_res_block(x, features, data_format=data_format)\n        skips.append(x)\n        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n\n        features = features * 2\n\n    x = rec_res_block(x, features, data_format=data_format)\n\n    for i in reversed(range(depth)):\n        features = features // 2\n        x = up_and_concate(x, skips[i], data_format=data_format)\n        x = rec_res_block(x, features, data_format=data_format)\n\n    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n    conv7 = core.Activation('sigmoid')(conv6)\n    model = Model(inputs=inputs, outputs=conv7)\n    #model.compile(optimizer=Adam(lr=1e-6), loss=[dice_coef_loss], metrics=['accuracy', dice_coef])\n    return model\n\n\n########################################################################################################\n#Attention R2U-Net\ndef att_r2_unet(img_w, img_h, n_label, data_format='channels_last'):\n    inputs = Input((img_w, img_h , 3))\n    x = inputs\n    depth = 4\n    features = 64\n    skips = []\n    for i in range(depth):\n        x = rec_res_block(x, features, data_format=data_format)\n        skips.append(x)\n        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n\n        features = features * 2\n\n    x = rec_res_block(x, features, data_format=data_format)\n\n    for i in reversed(range(depth)):\n        features = features // 2\n        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n        x = rec_res_block(x, features, data_format=data_format)\n\n    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n    conv7 = core.Activation('sigmoid')(conv6)\n    model = Model(inputs=inputs, outputs=conv7)\n    #model.compile(optimizer=Adam(lr=1e-6), loss=[dice_coef_loss], metrics=['accuracy', dice_coef])\n    return model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-26T11:33:13.807187Z","iopub.execute_input":"2021-07-26T11:33:13.807615Z","iopub.status.idle":"2021-07-26T11:33:13.880625Z","shell.execute_reply.started":"2021-07-26T11:33:13.807577Z","shell.execute_reply":"2021-07-26T11:33:13.879686Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"\nimport os\nimport numpy as np\nfrom glob import glob\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2021-07-26T11:33:13.882325Z","iopub.execute_input":"2021-07-26T11:33:13.882791Z","iopub.status.idle":"2021-07-26T11:33:13.887393Z","shell.execute_reply.started":"2021-07-26T11:33:13.882755Z","shell.execute_reply":"2021-07-26T11:33:13.886441Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport numpy as np\nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport cv2\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nBackGround = [255, 255, 255]\nroad = [0, 0, 0]\n# COLOR_DICT = np.array([BackGround, road])\none = [128, 128, 128]\ntwo = [128, 0, 0]\nthree = [192, 192, 128]\nfour = [255, 69, 0]\nfive = [128, 64, 128]\nsix = [60, 40, 222]\nseven = [128, 128, 0]\neight = [192, 128, 128]\nnine = [64, 64, 128]\nten = [64, 0, 128]\neleven = [64, 64, 0]\ntwelve = [0, 128, 192]\nCOLOR_DICT = np.array([one, two,three,four,five,six,seven,eight,nine,ten,eleven,twelve])\n\n\nclass data_preprocess:\n    def __init__(self, train_path=None, image_folder=None, label_folder=None,\n                 valid_path=None,valid_image_folder =None,valid_label_folder = None,\n                 test_path=None, save_path=None,\n                 img_rows=512, img_cols=512,\n                 flag_multi_class=False,\n                 num_classes = 2):\n        self.img_rows = img_rows\n        self.img_cols = img_cols\n        self.train_path = train_path\n        self.image_folder = image_folder\n        self.label_folder = label_folder\n        self.valid_path = valid_path\n        self.valid_image_folder = valid_image_folder\n        self.valid_label_folder = valid_label_folder\n        self.test_path = test_path\n        self.save_path = save_path\n        self.data_gen_args = dict(rotation_range=50,\n                                  vertical_flip=True,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\n        self.image_color_mode = \"rgb\"\n        self.label_color_mode = \"grayscale\"\n\n        self.flag_multi_class = flag_multi_class\n        self.num_class = num_classes\n        self.target_size = (img_cols, img_rows)\n        self.img_type = 'png'\n\n    def adjustData(self, img, label):\n        if (self.flag_multi_class):\n            img = img / 255.\n            label = label[:, :, :, 0] if (len(label.shape) == 4) else label[:, :, 0]\n            new_label = np.zeros(label.shape + (self.num_class,))\n            for i in range(self.num_class):\n                new_label[label == i, i] = 1\n            label = new_label\n        elif (np.max(img) > 1):\n            #img = img / 255.\n            #label = label / 255.\n            #label[label >= 0.5] = 1\n            #label[label < 0.5] = 0\n            img2 =np.asarray(img)\n            label2 =np.asarray(label)\n            img2 =img2.astype('float32')\n            label2 =label2.astype('float32')\n            img2 /= 255.0\n            label2 /= 255.0\n            label2[label2 >= 0.5] = 1\n            label2[label2 < 0.5] = 0\n        return (img2, label2)\n\n    def trainGenerator(self, batch_size, image_save_prefix=\"image\", label_save_prefix=\"label\",\n                       save_to_dir=None, seed=7):\n        '''\n        can generate image and label at the same time\n        use the same seed for image_datagen and label_datagen to ensure the transformation for image and label is the same\n        if you want to visualize the results of generator, set save_to_dir = \"your path\"\n        '''\n        image_datagen = ImageDataGenerator(**self.data_gen_args)\n        label_datagen = ImageDataGenerator(**self.data_gen_args)\n        image_generator = image_datagen.flow_from_directory(\n            self.train_path,\n            classes=[self.image_folder],\n            class_mode=None,\n            color_mode=self.image_color_mode,\n            target_size=self.target_size,\n            batch_size=batch_size,\n            save_to_dir=save_to_dir,\n            save_prefix=image_save_prefix,\n            seed=seed)\n        label_generator = label_datagen.flow_from_directory(\n            self.train_path,\n            classes=[self.label_folder],\n            class_mode=None,\n            color_mode=self.label_color_mode,\n            target_size=self.target_size,\n            batch_size=batch_size,\n            save_to_dir=save_to_dir,\n            save_prefix=label_save_prefix,\n            seed=seed)\n        train_generator = zip(image_generator, label_generator)\n        for (img, label) in train_generator:\n            img, label = self.adjustData(img, label)\n            yield (img, label)\n\n    def testGenerator(self):#no es usado por el momento\n        filenames = os.listdir(self.test_path)\n        for filename in filenames:\n            img = io.imread(os.path.join(self.test_path, filename), as_gray=False)\n            img = img / 255.\n            img = trans.resize(img, self.target_size, mode='constant')\n            img = np.reshape(img, img.shape + (1,)) if (not self.flag_multi_class) else img\n            img = np.reshape(img, (1,) + img.shape)\n            yield img\n\n    def validLoad(self, batch_size,seed=7):\n        image_datagen = ImageDataGenerator(rescale=0)\n        label_datagen = ImageDataGenerator(rescale=0)\n        image_generator = image_datagen.flow_from_directory(\n            self.valid_path,\n            classes=[self.valid_image_folder],\n            class_mode=None,\n            color_mode=self.image_color_mode,\n            target_size=self.target_size,\n            batch_size=batch_size,\n            seed=seed)\n        label_generator = label_datagen.flow_from_directory(\n            self.valid_path,\n            classes=[self.valid_label_folder],\n            class_mode=None,\n            color_mode=self.label_color_mode,\n            target_size=self.target_size,\n            batch_size=batch_size,\n            seed=seed)        \n        train_generator = zip(image_generator, label_generator)\n        for (img, label) in train_generator:\n            img, label = self.adjustData(img, label)\n            yield (img, label)\n        \n        # return imgs,labels\n\n    def saveResult(self, npyfile, size, name,threshold=80):#version alterna para guardar las predicciones\n        for i, item in enumerate(npyfile):\n            img = item\n            img_std = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n            if self.flag_multi_class:\n                for row in range(len(img)):\n                    for col in range(len(img[row])):\n                        num = np.argmax(img[row][col])\n                        img_std[row][col] = COLOR_DICT[num]\n            else:\n                for k in range(len(img)):\n                    for j in range(len(img[k])):\n                        num = img[k][j]\n                        if num < (threshold/255.0):\n                            img_std[k][j] = road\n                        else:\n                            img_std[k][j] = BackGround\n            img_std = cv2.resize(img_std, size, interpolation=cv2.INTER_CUBIC)\n            cv2.imwrite(os.path.join(self.save_path, (\"%s_predict.\" + self.img_type) % (name)), img_std)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T11:33:14.062944Z","iopub.execute_input":"2021-07-26T11:33:14.063447Z","iopub.status.idle":"2021-07-26T11:33:14.094733Z","shell.execute_reply.started":"2021-07-26T11:33:14.063418Z","shell.execute_reply":"2021-07-26T11:33:14.093650Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\nfrom keras.losses import binary_crossentropy\nimport tensorflow as tf\nimport numpy as np\ndef dice_coeff(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return score\ndef dice_loss(y_true, y_pred):\n    loss = 1 - dice_coeff(y_true, y_pred)\n    return loss\ndef iou_coeff(y_true, y_pred):\n    smooth=1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    union=K.sum(y_true_f) + K.sum(y_pred_f)-intersection\n    mvalue=(intersection+smooth)/(union+smooth)\n    return mvalue\ndef precision(y_true, y_pred):\n    \"\"\"Precision metric.\n    Only computes a batch-wise average of precision.\n    Computes the precision, a metric for multi-label classification of\n    how many selected items are relevant.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\ndef recall(y_true, y_pred):\n        \"\"\"Recall metric.\n        Only computes a batch-wise average of recall.\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\ndef ACL5(y_true, y_pred): \n\n\t#y_pred = K.cast(y_pred, dtype = 'float64')\n\n\tprint(K.int_shape(y_pred))\n\n\tx = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:] # horizontal and vertical directions \n\ty = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n\n\tdelta_x = x[:,1:,:-2,:]**2\n\tdelta_y = y[:,:-2,1:,:]**2\n\tdelta_u = K.abs(delta_x + delta_y) \n\n\tepsilon = 0.00000001 # where is a parameter to avoid square root is zero in practice.\n\tw = 1####\n\tlenth = w * K.sum(K.sqrt(delta_u + epsilon)) # equ.(11) in the paper\n\n\n\tC_1 = np.ones((512, 512))\n\tC_2 = np.zeros((512, 512))\n\n\tregion_in = K.abs(K.sum( y_pred[:,:,:,0] * ((y_true[:,:,:,0] - C_1)**2) ) ) # equ.(12) in the paper\n\tregion_out = K.abs(K.sum( (1-y_pred[:,:,:,0]) * ((y_true[:,:,:,0] - C_2)**2) )) # equ.(12) in the paper\n\n\tlambdaP = 5 # lambda parameter could be various.\n\t\n\tloss =  lenth + lambdaP * ((region_in) + (region_out)) \n\n\treturn loss","metadata":{"execution":{"iopub.status.busy":"2021-07-26T11:33:14.096479Z","iopub.execute_input":"2021-07-26T11:33:14.096926Z","iopub.status.idle":"2021-07-26T11:33:14.117116Z","shell.execute_reply.started":"2021-07-26T11:33:14.096787Z","shell.execute_reply":"2021-07-26T11:33:14.116288Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport keras\nfrom keras.callbacks import TensorBoard\nimport tensorflow as tf\n#import keras.backend.tensorflow_backend as K\nimport matplotlib.pyplot as plt\nfrom keras.callbacks import CSVLogger\n\nnp.random.seed(42)\ntf.random.set_seed(42)\n    \n#config = tf.ConfigProto()\n#config.gpu_options.allow_growth=True\n#sess = tf.Session(config=config)\n#K.set_session(sess)\n #os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\n\n#path to images which are prepared to train a model\ntrain_path = \"../input/training/training\"\nimage_folder = \"images\"\nlabel_folder = \"label\"\nvalid_path =  \"../input/validation/Validation\"\nvalid_image_folder =\"images\"\nvalid_label_folder = \"label\"\nlog_filepath = './log'\nflag_multi_class = False\nnum_classes = 2\nlr = 8.00E-05\nbatch = 2\n\n\n\nopt = tf.keras.optimizers.Adam(lr , beta_1=0.9,\n    beta_2=0.999)\n\ndp = data_preprocess(train_path=train_path,image_folder=image_folder,label_folder=label_folder,\n                     valid_path=valid_path,valid_image_folder=valid_image_folder,valid_label_folder=valid_label_folder,\n                     flag_multi_class=flag_multi_class,\n                     num_classes=num_classes)\n\ntrain_data = dp.trainGenerator(batch_size=2)\nvalid_data = dp.validLoad(batch_size=2)\n#Number Of Batches\n#rain_steps = len(train_data)//batch\n#valid_steps = len(valid_data)//batch\n\n\n#if len(train_data) % batch != 0:\n#        train_steps += 1\n#if len(valid_data) % batch != 0:\n#        valid_steps += 1\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T11:33:14.120088Z","iopub.execute_input":"2021-07-26T11:33:14.120369Z","iopub.status.idle":"2021-07-26T11:33:14.131565Z","shell.execute_reply.started":"2021-07-26T11:33:14.120327Z","shell.execute_reply":"2021-07-26T11:33:14.130607Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"\nbeta = 0.25\nalpha = 0.25\ngamma = 2\nepsilon = 1e-5\nsmooth = 1\n\ndef tversky_index( y_true, y_pred):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n    alpha = 0.7\n    return (true_pos + smooth) / (true_pos + alpha * false_neg + (\n                1 - alpha) * false_pos + smooth)\n\ndef tversky_loss( y_true, y_pred):\n    return 1 - tversky_index(y_true, y_pred)\n\ndef focal_tversky( y_true, y_pred):\n    pt_1 = tversky_index(y_true, y_pred)\n    gamma = 0.75\n    return K.pow((1 - pt_1), gamma)\n\ndef dsc(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return score\n\ndef dice_loss(y_true, y_pred):\n    loss = 1 - dsc(y_true, y_pred)\n    return loss\n\ndef bce_dice_loss(y_true, y_pred):\n    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-07-26T11:33:14.134737Z","iopub.execute_input":"2021-07-26T11:33:14.134977Z","iopub.status.idle":"2021-07-26T11:33:14.143531Z","shell.execute_reply.started":"2021-07-26T11:33:14.134955Z","shell.execute_reply":"2021-07-26T11:33:14.142542Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-07-26T11:33:14.144888Z","iopub.execute_input":"2021-07-26T11:33:14.145279Z","iopub.status.idle":"2021-07-26T11:33:14.157267Z","shell.execute_reply.started":"2021-07-26T11:33:14.145241Z","shell.execute_reply":"2021-07-26T11:33:14.156421Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"from keras.models import *\nfrom keras.layers import Input, Conv2D, UpSampling2D, BatchNormalization, Activation, add,average,concatenate\nfrom keras.layers.core import Lambda\nfrom keras.optimizers import *\nfrom keras.losses import binary_crossentropy\n\n\n\nIMG_SIZE = 512\nh_heuns_method=0.5\n\ndef res_block(x, nb_filters, strides):\n    res_path = BatchNormalization()(x)\n    res_path = Activation(activation='relu')(res_path)\n    res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same' ,strides=strides[0])(res_path)\n\n    res_path = BatchNormalization()(res_path)\n    res_path = Activation(activation='relu')(res_path)\n    res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same',strides=strides[1])(res_path)\n    hpath = Lambda(lambda x: x * h_heuns_method)(res_path)\n\n    shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1),strides=strides[0])(x)\n    shortcut = BatchNormalization()(shortcut)\n\n    res_path = add([shortcut, hpath])#suma corta\n    return res_path\ndef res_block2(x,y,nb_filters, strides):\n    res_path = BatchNormalization()(x)\n    res_path = Activation(activation='relu')(res_path)\n    res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same' ,strides=strides[0])(res_path)\n\n    res_path = BatchNormalization()(res_path)\n    res_path = Activation(activation='relu')(res_path)\n    res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same',strides=strides[1])(res_path)\n    hpath = Lambda(lambda x: x * h_heuns_method)(res_path)\n\n    shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1),strides=strides[0])(x)\n    shortcut = BatchNormalization()(shortcut)\n\n    res_path = add([shortcut, hpath])#suma corta\n\n    res_path = average([y, res_path])#suma doble \n    return res_path\n\n\ndef encoder(x):\n    to_decoder = []\n\n    main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1))(x)\n    main_path = BatchNormalization()(main_path)\n    main_path = Activation(activation='relu')(main_path)\n\n    main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1))(main_path)\n    hpath = Lambda(lambda x: x * h_heuns_method)(main_path)\n\n    shortcut = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1))(x)\n    shortcut = BatchNormalization()(shortcut)\n\n    main_path = add([shortcut, hpath])#suma corta\n\n    to_decoder.append(main_path)\n\n\n    s1 = Conv2D(filters=128, kernel_size=(1, 1), strides=(2, 2))(x)\n    s1 = BatchNormalization()(s1)\n\n    main_path = res_block2(main_path,s1, [128, 128], [(2, 2), (1, 1)]) \n    to_decoder.append(main_path)\n\n    main_path = res_block(main_path, [256, 256], [(2, 2), (1, 1)])\n    to_decoder.append(main_path)\n\n    s2 = Conv2D(filters=512, kernel_size=(1, 1), strides=(4, 4))(to_decoder[1])\n    s2 = BatchNormalization()(s2)\n\n    main_path = res_block2(main_path,s2, [512, 512], [(2, 2), (1, 1)])\n    to_decoder.append(main_path)\n\n    return to_decoder\n\n\ndef decoder(x, from_encoder):\n    main_path = UpSampling2D(size=(2, 2))(x)#32x32\n    main_path1 = concatenate([main_path, from_encoder[3]], axis=3)\n    main_path = res_block(main_path1, [512, 512], [(1, 1), (1, 1)])\n\n    main_path = UpSampling2D(size=(2, 2))(main_path)###64x64\n    main_path = concatenate([main_path, from_encoder[2]], axis=3)#\n    u1 = UpSampling2D(size=(2, 2))(main_path1)#\n    u1 = Conv2D(256, kernel_size=(1, 1),strides=(1, 1))(u1)\n    u1 = BatchNormalization()(u1)\n    main_path = res_block2(main_path,u1, [256, 256], [(1, 1), (1, 1)])#\n\n    main_path = UpSampling2D(size=(2, 2))(main_path)#128x128\n    main_path2 = concatenate([main_path, from_encoder[1]], axis=3)#\n    main_path = res_block(main_path2, [128, 128], [(1, 1), (1, 1)])#\n\n    main_path = UpSampling2D(size=(2, 2))(main_path)#256x256\n    main_path = concatenate([main_path, from_encoder[0]], axis=3)#256x256\n\n    u2 = UpSampling2D(size=(2,2))(main_path2)#\n    u2 = Conv2D(64, kernel_size=(1, 1),strides=(1, 1))(u2)#\n    u2 = BatchNormalization()(u2)\n    main_path = res_block2(main_path,u2, [64, 64], [(1, 1), (1, 1)])#256x256\n\n    return main_path\n\n\ndef res2unet(lrate=8.00E-05,pretrained_weights=None):\n    print(lrate)\n    input_size=(512, 512, 3)\n    inputs = Input(shape=input_size)\n\n    to_decoder = encoder(inputs)\n\n    path = res_block(to_decoder[3], [1024, 1024], [(2, 2), (1, 1)])####bridge\n\n    path = decoder(path, from_encoder=to_decoder)\n\n\n    path = Conv2D(2, kernel_size=(3, 3),activation='relu', padding='same', strides=(1, 1))(path)\n    path = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(path)\n    model = Model(inputs=inputs, outputs=path)\n    #model.compile(optimizer=Adam(lr=lrate), loss=ACL5, metrics=[dice_loss,iou_coeff,precision,recall])\n    #model.summary()\n    if (pretrained_weights):\n        model.load_weights(pretrained_weights)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-26T11:33:14.158565Z","iopub.execute_input":"2021-07-26T11:33:14.158900Z","iopub.status.idle":"2021-07-26T11:33:14.189668Z","shell.execute_reply.started":"2021-07-26T11:33:14.158866Z","shell.execute_reply":"2021-07-26T11:33:14.188828Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"pip install segmentation_models\nimport segmentation_models\nfrom segmentation_models.losses import bce_jaccard_loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nimg_w  , img_h = 512 , 512\nn_label = 1\nmodel =res2unet(lrate=8.00E-05,pretrained_weights=None)\n#model = unet(lrate=1e-4,ls=2)# WBCE\n#model = att_r2_unet(img_w, img_h, n_label, data_format='channels_last')\nmetrics = [\"acc\" , recall , precision  , iou_coeff ,dice_loss]\nmodel_checkpoint1 = keras.callbacks.ModelCheckpoint('Res2Net.hdf5', monitor= 'val_iou_coeff' ,verbose=1,mode='min',save_best_only=True)#para guardar el entranamiento con menor dice loss en validation\n#steps_per_epochnumber= 600 / 2\n#validation_stepsnumber = 200 / 2\n\ncsv_logger = CSVLogger('trainingRes2Net.log', append=True, separator=';')#respaldo de datos de entranamiento \nmodel.compile(optimizer= opt, loss=ACL5, metrics=[\"acc\" , recall , precision , iou_coeff ,dice_loss])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T11:33:14.190812Z","iopub.execute_input":"2021-07-26T11:33:14.191408Z","iopub.status.idle":"2021-07-26T11:33:14.835856Z","shell.execute_reply.started":"2021-07-26T11:33:14.191371Z","shell.execute_reply":"2021-07-26T11:33:14.834995Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"8e-05\nModel: \"model_7\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_15 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d_763 (Conv2D)             (None, 512, 512, 64) 1792        input_15[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_210 (BatchN (None, 512, 512, 64) 256         conv2d_763[0][0]                 \n__________________________________________________________________________________________________\nactivation_560 (Activation)     (None, 512, 512, 64) 0           batch_normalization_210[0][0]    \n__________________________________________________________________________________________________\nconv2d_765 (Conv2D)             (None, 512, 512, 64) 256         input_15[0][0]                   \n__________________________________________________________________________________________________\nconv2d_764 (Conv2D)             (None, 512, 512, 64) 36928       activation_560[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_211 (BatchN (None, 512, 512, 64) 256         conv2d_765[0][0]                 \n__________________________________________________________________________________________________\nlambda_91 (Lambda)              (None, 512, 512, 64) 0           conv2d_764[0][0]                 \n__________________________________________________________________________________________________\nadd_406 (Add)                   (None, 512, 512, 64) 0           batch_normalization_211[0][0]    \n                                                                 lambda_91[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_213 (BatchN (None, 512, 512, 64) 256         add_406[0][0]                    \n__________________________________________________________________________________________________\nactivation_561 (Activation)     (None, 512, 512, 64) 0           batch_normalization_213[0][0]    \n__________________________________________________________________________________________________\nconv2d_767 (Conv2D)             (None, 256, 256, 128 73856       activation_561[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_214 (BatchN (None, 256, 256, 128 512         conv2d_767[0][0]                 \n__________________________________________________________________________________________________\nactivation_562 (Activation)     (None, 256, 256, 128 0           batch_normalization_214[0][0]    \n__________________________________________________________________________________________________\nconv2d_769 (Conv2D)             (None, 256, 256, 128 8320        add_406[0][0]                    \n__________________________________________________________________________________________________\nconv2d_768 (Conv2D)             (None, 256, 256, 128 147584      activation_562[0][0]             \n__________________________________________________________________________________________________\nconv2d_766 (Conv2D)             (None, 256, 256, 128 512         input_15[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_215 (BatchN (None, 256, 256, 128 512         conv2d_769[0][0]                 \n__________________________________________________________________________________________________\nlambda_92 (Lambda)              (None, 256, 256, 128 0           conv2d_768[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_212 (BatchN (None, 256, 256, 128 512         conv2d_766[0][0]                 \n__________________________________________________________________________________________________\nadd_407 (Add)                   (None, 256, 256, 128 0           batch_normalization_215[0][0]    \n                                                                 lambda_92[0][0]                  \n__________________________________________________________________________________________________\naverage_28 (Average)            (None, 256, 256, 128 0           batch_normalization_212[0][0]    \n                                                                 add_407[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_216 (BatchN (None, 256, 256, 128 512         average_28[0][0]                 \n__________________________________________________________________________________________________\nactivation_563 (Activation)     (None, 256, 256, 128 0           batch_normalization_216[0][0]    \n__________________________________________________________________________________________________\nconv2d_770 (Conv2D)             (None, 128, 128, 256 295168      activation_563[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_217 (BatchN (None, 128, 128, 256 1024        conv2d_770[0][0]                 \n__________________________________________________________________________________________________\nactivation_564 (Activation)     (None, 128, 128, 256 0           batch_normalization_217[0][0]    \n__________________________________________________________________________________________________\nconv2d_772 (Conv2D)             (None, 128, 128, 256 33024       average_28[0][0]                 \n__________________________________________________________________________________________________\nconv2d_771 (Conv2D)             (None, 128, 128, 256 590080      activation_564[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_218 (BatchN (None, 128, 128, 256 1024        conv2d_772[0][0]                 \n__________________________________________________________________________________________________\nlambda_93 (Lambda)              (None, 128, 128, 256 0           conv2d_771[0][0]                 \n__________________________________________________________________________________________________\nadd_408 (Add)                   (None, 128, 128, 256 0           batch_normalization_218[0][0]    \n                                                                 lambda_93[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_220 (BatchN (None, 128, 128, 256 1024        add_408[0][0]                    \n__________________________________________________________________________________________________\nactivation_565 (Activation)     (None, 128, 128, 256 0           batch_normalization_220[0][0]    \n__________________________________________________________________________________________________\nconv2d_774 (Conv2D)             (None, 64, 64, 512)  1180160     activation_565[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_221 (BatchN (None, 64, 64, 512)  2048        conv2d_774[0][0]                 \n__________________________________________________________________________________________________\nactivation_566 (Activation)     (None, 64, 64, 512)  0           batch_normalization_221[0][0]    \n__________________________________________________________________________________________________\nconv2d_776 (Conv2D)             (None, 64, 64, 512)  131584      add_408[0][0]                    \n__________________________________________________________________________________________________\nconv2d_775 (Conv2D)             (None, 64, 64, 512)  2359808     activation_566[0][0]             \n__________________________________________________________________________________________________\nconv2d_773 (Conv2D)             (None, 64, 64, 512)  66048       average_28[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_222 (BatchN (None, 64, 64, 512)  2048        conv2d_776[0][0]                 \n__________________________________________________________________________________________________\nlambda_94 (Lambda)              (None, 64, 64, 512)  0           conv2d_775[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_219 (BatchN (None, 64, 64, 512)  2048        conv2d_773[0][0]                 \n__________________________________________________________________________________________________\nadd_409 (Add)                   (None, 64, 64, 512)  0           batch_normalization_222[0][0]    \n                                                                 lambda_94[0][0]                  \n__________________________________________________________________________________________________\naverage_29 (Average)            (None, 64, 64, 512)  0           batch_normalization_219[0][0]    \n                                                                 add_409[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_223 (BatchN (None, 64, 64, 512)  2048        average_29[0][0]                 \n__________________________________________________________________________________________________\nactivation_567 (Activation)     (None, 64, 64, 512)  0           batch_normalization_223[0][0]    \n__________________________________________________________________________________________________\nconv2d_777 (Conv2D)             (None, 32, 32, 1024) 4719616     activation_567[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_224 (BatchN (None, 32, 32, 1024) 4096        conv2d_777[0][0]                 \n__________________________________________________________________________________________________\nactivation_568 (Activation)     (None, 32, 32, 1024) 0           batch_normalization_224[0][0]    \n__________________________________________________________________________________________________\nconv2d_779 (Conv2D)             (None, 32, 32, 1024) 525312      average_29[0][0]                 \n__________________________________________________________________________________________________\nconv2d_778 (Conv2D)             (None, 32, 32, 1024) 9438208     activation_568[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_225 (BatchN (None, 32, 32, 1024) 4096        conv2d_779[0][0]                 \n__________________________________________________________________________________________________\nlambda_95 (Lambda)              (None, 32, 32, 1024) 0           conv2d_778[0][0]                 \n__________________________________________________________________________________________________\nadd_410 (Add)                   (None, 32, 32, 1024) 0           batch_normalization_225[0][0]    \n                                                                 lambda_95[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_70 (UpSampling2D) (None, 64, 64, 1024) 0           add_410[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_28 (Concatenate)    (None, 64, 64, 1536) 0           up_sampling2d_70[0][0]           \n                                                                 average_29[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_226 (BatchN (None, 64, 64, 1536) 6144        concatenate_28[0][0]             \n__________________________________________________________________________________________________\nactivation_569 (Activation)     (None, 64, 64, 1536) 0           batch_normalization_226[0][0]    \n__________________________________________________________________________________________________\nconv2d_780 (Conv2D)             (None, 64, 64, 512)  7078400     activation_569[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_227 (BatchN (None, 64, 64, 512)  2048        conv2d_780[0][0]                 \n__________________________________________________________________________________________________\nactivation_570 (Activation)     (None, 64, 64, 512)  0           batch_normalization_227[0][0]    \n__________________________________________________________________________________________________\nconv2d_782 (Conv2D)             (None, 64, 64, 512)  786944      concatenate_28[0][0]             \n__________________________________________________________________________________________________\nconv2d_781 (Conv2D)             (None, 64, 64, 512)  2359808     activation_570[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_228 (BatchN (None, 64, 64, 512)  2048        conv2d_782[0][0]                 \n__________________________________________________________________________________________________\nlambda_96 (Lambda)              (None, 64, 64, 512)  0           conv2d_781[0][0]                 \n__________________________________________________________________________________________________\nadd_411 (Add)                   (None, 64, 64, 512)  0           batch_normalization_228[0][0]    \n                                                                 lambda_96[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_71 (UpSampling2D) (None, 128, 128, 512 0           add_411[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_29 (Concatenate)    (None, 128, 128, 768 0           up_sampling2d_71[0][0]           \n                                                                 add_408[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_230 (BatchN (None, 128, 128, 768 3072        concatenate_29[0][0]             \n__________________________________________________________________________________________________\nactivation_571 (Activation)     (None, 128, 128, 768 0           batch_normalization_230[0][0]    \n__________________________________________________________________________________________________\nconv2d_784 (Conv2D)             (None, 128, 128, 256 1769728     activation_571[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_231 (BatchN (None, 128, 128, 256 1024        conv2d_784[0][0]                 \n__________________________________________________________________________________________________\nactivation_572 (Activation)     (None, 128, 128, 256 0           batch_normalization_231[0][0]    \n__________________________________________________________________________________________________\nup_sampling2d_72 (UpSampling2D) (None, 128, 128, 153 0           concatenate_28[0][0]             \n__________________________________________________________________________________________________\nconv2d_786 (Conv2D)             (None, 128, 128, 256 196864      concatenate_29[0][0]             \n__________________________________________________________________________________________________\nconv2d_785 (Conv2D)             (None, 128, 128, 256 590080      activation_572[0][0]             \n__________________________________________________________________________________________________\nconv2d_783 (Conv2D)             (None, 128, 128, 256 393472      up_sampling2d_72[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_232 (BatchN (None, 128, 128, 256 1024        conv2d_786[0][0]                 \n__________________________________________________________________________________________________\nlambda_97 (Lambda)              (None, 128, 128, 256 0           conv2d_785[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_229 (BatchN (None, 128, 128, 256 1024        conv2d_783[0][0]                 \n__________________________________________________________________________________________________\nadd_412 (Add)                   (None, 128, 128, 256 0           batch_normalization_232[0][0]    \n                                                                 lambda_97[0][0]                  \n__________________________________________________________________________________________________\naverage_30 (Average)            (None, 128, 128, 256 0           batch_normalization_229[0][0]    \n                                                                 add_412[0][0]                    \n__________________________________________________________________________________________________\nup_sampling2d_73 (UpSampling2D) (None, 256, 256, 256 0           average_30[0][0]                 \n__________________________________________________________________________________________________\nconcatenate_30 (Concatenate)    (None, 256, 256, 384 0           up_sampling2d_73[0][0]           \n                                                                 average_28[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_233 (BatchN (None, 256, 256, 384 1536        concatenate_30[0][0]             \n__________________________________________________________________________________________________\nactivation_573 (Activation)     (None, 256, 256, 384 0           batch_normalization_233[0][0]    \n__________________________________________________________________________________________________\nconv2d_787 (Conv2D)             (None, 256, 256, 128 442496      activation_573[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_234 (BatchN (None, 256, 256, 128 512         conv2d_787[0][0]                 \n__________________________________________________________________________________________________\nactivation_574 (Activation)     (None, 256, 256, 128 0           batch_normalization_234[0][0]    \n__________________________________________________________________________________________________\nconv2d_789 (Conv2D)             (None, 256, 256, 128 49280       concatenate_30[0][0]             \n__________________________________________________________________________________________________\nconv2d_788 (Conv2D)             (None, 256, 256, 128 147584      activation_574[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_235 (BatchN (None, 256, 256, 128 512         conv2d_789[0][0]                 \n__________________________________________________________________________________________________\nlambda_98 (Lambda)              (None, 256, 256, 128 0           conv2d_788[0][0]                 \n__________________________________________________________________________________________________\nadd_413 (Add)                   (None, 256, 256, 128 0           batch_normalization_235[0][0]    \n                                                                 lambda_98[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_74 (UpSampling2D) (None, 512, 512, 128 0           add_413[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_31 (Concatenate)    (None, 512, 512, 192 0           up_sampling2d_74[0][0]           \n                                                                 add_406[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_237 (BatchN (None, 512, 512, 192 768         concatenate_31[0][0]             \n__________________________________________________________________________________________________\nactivation_575 (Activation)     (None, 512, 512, 192 0           batch_normalization_237[0][0]    \n__________________________________________________________________________________________________\nconv2d_791 (Conv2D)             (None, 512, 512, 64) 110656      activation_575[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_238 (BatchN (None, 512, 512, 64) 256         conv2d_791[0][0]                 \n__________________________________________________________________________________________________\nactivation_576 (Activation)     (None, 512, 512, 64) 0           batch_normalization_238[0][0]    \n__________________________________________________________________________________________________\nup_sampling2d_75 (UpSampling2D) (None, 512, 512, 384 0           concatenate_30[0][0]             \n__________________________________________________________________________________________________\nconv2d_793 (Conv2D)             (None, 512, 512, 64) 12352       concatenate_31[0][0]             \n__________________________________________________________________________________________________\nconv2d_792 (Conv2D)             (None, 512, 512, 64) 36928       activation_576[0][0]             \n__________________________________________________________________________________________________\nconv2d_790 (Conv2D)             (None, 512, 512, 64) 24640       up_sampling2d_75[0][0]           \n__________________________________________________________________________________________________\nbatch_normalization_239 (BatchN (None, 512, 512, 64) 256         conv2d_793[0][0]                 \n__________________________________________________________________________________________________\nlambda_99 (Lambda)              (None, 512, 512, 64) 0           conv2d_792[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_236 (BatchN (None, 512, 512, 64) 256         conv2d_790[0][0]                 \n__________________________________________________________________________________________________\nadd_414 (Add)                   (None, 512, 512, 64) 0           batch_normalization_239[0][0]    \n                                                                 lambda_99[0][0]                  \n__________________________________________________________________________________________________\naverage_31 (Average)            (None, 512, 512, 64) 0           batch_normalization_236[0][0]    \n                                                                 add_414[0][0]                    \n__________________________________________________________________________________________________\nconv2d_794 (Conv2D)             (None, 512, 512, 2)  1154        average_31[0][0]                 \n__________________________________________________________________________________________________\nconv2d_795 (Conv2D)             (None, 512, 512, 1)  3           conv2d_794[0][0]                 \n==================================================================================================\nTotal params: 33,651,397\nTrainable params: 33,630,021\nNon-trainable params: 21,376\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit_generator(train_data,\n                              epochs=32,\n                              steps_per_epoch=300,\n                              validation_steps=100,\n                              validation_data=valid_data,\n                              callbacks=[model_checkpoint1 , ReduceLROnPlateau(monitor='iou_coeff', factor=0.1, patience=4)])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T11:33:14.837849Z","iopub.execute_input":"2021-07-26T11:33:14.838175Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Found 600 images belonging to 1 classes.\nFound 600 images belonging to 1 classes.\nEpoch 1/32\n(None, 512, 512, 1)\n(None, 512, 512, 1)\n300/300 [==============================] - ETA: 0s - loss: 317380.9019 - acc: 0.9666 - recall: 0.1278 - precision: 0.2372 - iou_coeff: 0.0939 - dice_loss: 0.8405Found 200 images belonging to 1 classes.\nFound 200 images belonging to 1 classes.\n(None, 512, 512, 1)\n300/300 [==============================] - 169s 540ms/step - loss: 316778.6266 - acc: 0.9667 - recall: 0.1282 - precision: 0.2379 - iou_coeff: 0.0942 - dice_loss: 0.8401 - val_loss: 38590.3594 - val_acc: 0.9867 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - val_iou_coeff: 0.0013 - val_dice_loss: 0.9976\n\nEpoch 00001: val_iou_coeff improved from inf to 0.00128, saving model to Res2Net.hdf5\nEpoch 2/32\n300/300 [==============================] - 161s 537ms/step - loss: 27936.0998 - acc: 0.9904 - recall: 0.4858 - precision: 0.7051 - iou_coeff: 0.3618 - dice_loss: 0.4856 - val_loss: 34226.2031 - val_acc: 0.9874 - val_recall: 0.0688 - val_precision: 0.4743 - val_iou_coeff: 0.0585 - val_dice_loss: 0.9028\n\nEpoch 00002: val_iou_coeff did not improve from 0.00128\nEpoch 3/32\n300/300 [==============================] - 161s 536ms/step - loss: 24962.9524 - acc: 0.9911 - recall: 0.5274 - precision: 0.7345 - iou_coeff: 0.4250 - dice_loss: 0.4238 - val_loss: 26441.5723 - val_acc: 0.9905 - val_recall: 0.4348 - val_precision: 0.7376 - val_iou_coeff: 0.3632 - val_dice_loss: 0.4902\n\nEpoch 00003: val_iou_coeff did not improve from 0.00128\nEpoch 4/32\n300/300 [==============================] - 161s 536ms/step - loss: 23567.3617 - acc: 0.9914 - recall: 0.5290 - precision: 0.7590 - iou_coeff: 0.4433 - dice_loss: 0.4030 - val_loss: 31737.6152 - val_acc: 0.9882 - val_recall: 0.7507 - val_precision: 0.5785 - val_iou_coeff: 0.4797 - val_dice_loss: 0.3644\n\nEpoch 00004: val_iou_coeff did not improve from 0.00128\nEpoch 5/32\n300/300 [==============================] - 161s 537ms/step - loss: 21082.5437 - acc: 0.9923 - recall: 0.5818 - precision: 0.7601 - iou_coeff: 0.4831 - dice_loss: 0.3638 - val_loss: 21694.2070 - val_acc: 0.9921 - val_recall: 0.4739 - val_precision: 0.8219 - val_iou_coeff: 0.4252 - val_dice_loss: 0.4301\n\nEpoch 00005: val_iou_coeff did not improve from 0.00128\nEpoch 6/32\n300/300 [==============================] - 161s 537ms/step - loss: 19038.1715 - acc: 0.9931 - recall: 0.6314 - precision: 0.7907 - iou_coeff: 0.5316 - dice_loss: 0.3177 - val_loss: 20700.4883 - val_acc: 0.9925 - val_recall: 0.6378 - val_precision: 0.7681 - val_iou_coeff: 0.5261 - val_dice_loss: 0.3270\n\nEpoch 00006: val_iou_coeff did not improve from 0.00128\nEpoch 7/32\n300/300 [==============================] - 161s 537ms/step - loss: 19304.6728 - acc: 0.9930 - recall: 0.6403 - precision: 0.7949 - iou_coeff: 0.5440 - dice_loss: 0.3075 - val_loss: 19763.5410 - val_acc: 0.9928 - val_recall: 0.5805 - val_precision: 0.8089 - val_iou_coeff: 0.5085 - val_dice_loss: 0.3467\n\nEpoch 00007: val_iou_coeff did not improve from 0.00128\nEpoch 8/32\n300/300 [==============================] - 161s 536ms/step - loss: 19702.5375 - acc: 0.9928 - recall: 0.6240 - precision: 0.7992 - iou_coeff: 0.5346 - dice_loss: 0.3167 - val_loss: 19478.1230 - val_acc: 0.9929 - val_recall: 0.5714 - val_precision: 0.8248 - val_iou_coeff: 0.5070 - val_dice_loss: 0.3479\n\nEpoch 00008: val_iou_coeff did not improve from 0.00128\nEpoch 9/32\n300/300 [==============================] - 161s 537ms/step - loss: 18294.9770 - acc: 0.9934 - recall: 0.6611 - precision: 0.8083 - iou_coeff: 0.5699 - dice_loss: 0.2871 - val_loss: 18970.0547 - val_acc: 0.9931 - val_recall: 0.6498 - val_precision: 0.8144 - val_iou_coeff: 0.5543 - val_dice_loss: 0.2982\n\nEpoch 00009: val_iou_coeff did not improve from 0.00128\nEpoch 10/32\n300/300 [==============================] - 161s 537ms/step - loss: 17969.6548 - acc: 0.9935 - recall: 0.6728 - precision: 0.8132 - iou_coeff: 0.5756 - dice_loss: 0.2792 - val_loss: 19187.2676 - val_acc: 0.9930 - val_recall: 0.6416 - val_precision: 0.7996 - val_iou_coeff: 0.5411 - val_dice_loss: 0.3113\n\nEpoch 00010: val_iou_coeff did not improve from 0.00128\nEpoch 11/32\n300/300 [==============================] - 161s 537ms/step - loss: 17088.1653 - acc: 0.9938 - recall: 0.6782 - precision: 0.8187 - iou_coeff: 0.5850 - dice_loss: 0.2721 - val_loss: 18845.3809 - val_acc: 0.9932 - val_recall: 0.6308 - val_precision: 0.8089 - val_iou_coeff: 0.5453 - val_dice_loss: 0.3127\n\nEpoch 00011: val_iou_coeff did not improve from 0.00128\nEpoch 12/32\n300/300 [==============================] - 161s 537ms/step - loss: 17000.3440 - acc: 0.9939 - recall: 0.6720 - precision: 0.8196 - iou_coeff: 0.5831 - dice_loss: 0.2743 - val_loss: 18991.3828 - val_acc: 0.9931 - val_recall: 0.6137 - val_precision: 0.8413 - val_iou_coeff: 0.5340 - val_dice_loss: 0.3179\n\nEpoch 00012: val_iou_coeff did not improve from 0.00128\nEpoch 13/32\n300/300 [==============================] - 161s 537ms/step - loss: 17774.2123 - acc: 0.9936 - recall: 0.6765 - precision: 0.8227 - iou_coeff: 0.5849 - dice_loss: 0.2726 - val_loss: 19239.3691 - val_acc: 0.9930 - val_recall: 0.6145 - val_precision: 0.8325 - val_iou_coeff: 0.5379 - val_dice_loss: 0.3167\n\nEpoch 00013: val_iou_coeff did not improve from 0.00128\nEpoch 14/32\n300/300 [==============================] - 161s 536ms/step - loss: 18889.7691 - acc: 0.9931 - recall: 0.6239 - precision: 0.8039 - iou_coeff: 0.5459 - dice_loss: 0.3123 - val_loss: 18722.0039 - val_acc: 0.9932 - val_recall: 0.6266 - val_precision: 0.8255 - val_iou_coeff: 0.5424 - val_dice_loss: 0.3119\n\nEpoch 00014: val_iou_coeff did not improve from 0.00128\nEpoch 15/32\n300/300 [==============================] - 161s 536ms/step - loss: 18168.5033 - acc: 0.9934 - recall: 0.6506 - precision: 0.8307 - iou_coeff: 0.5701 - dice_loss: 0.2856 - val_loss: 19480.4492 - val_acc: 0.9929 - val_recall: 0.6111 - val_precision: 0.8095 - val_iou_coeff: 0.5297 - val_dice_loss: 0.3241\n\nEpoch 00015: val_iou_coeff did not improve from 0.00128\nEpoch 16/32\n300/300 [==============================] - 161s 537ms/step - loss: 17601.0254 - acc: 0.9936 - recall: 0.6655 - precision: 0.8197 - iou_coeff: 0.5789 - dice_loss: 0.2788 - val_loss: 18508.6562 - val_acc: 0.9933 - val_recall: 0.6571 - val_precision: 0.8248 - val_iou_coeff: 0.5652 - val_dice_loss: 0.2910\n\nEpoch 00016: val_iou_coeff did not improve from 0.00128\nEpoch 17/32\n300/300 [==============================] - 161s 537ms/step - loss: 17796.9064 - acc: 0.9936 - recall: 0.6617 - precision: 0.8131 - iou_coeff: 0.5710 - dice_loss: 0.2856 - val_loss: 18531.7129 - val_acc: 0.9933 - val_recall: 0.6305 - val_precision: 0.8317 - val_iou_coeff: 0.5455 - val_dice_loss: 0.3061\n\nEpoch 00017: val_iou_coeff did not improve from 0.00128\nEpoch 18/32\n300/300 [==============================] - 161s 536ms/step - loss: 17857.0717 - acc: 0.9936 - recall: 0.6675 - precision: 0.8276 - iou_coeff: 0.5807 - dice_loss: 0.2750 - val_loss: 19152.2578 - val_acc: 0.9931 - val_recall: 0.6356 - val_precision: 0.8095 - val_iou_coeff: 0.5460 - val_dice_loss: 0.3125\n\nEpoch 00018: val_iou_coeff did not improve from 0.00128\nEpoch 19/32\n300/300 [==============================] - 161s 537ms/step - loss: 17888.8470 - acc: 0.9935 - recall: 0.6507 - precision: 0.8203 - iou_coeff: 0.5655 - dice_loss: 0.2914 - val_loss: 18463.8184 - val_acc: 0.9933 - val_recall: 0.6258 - val_precision: 0.8276 - val_iou_coeff: 0.5374 - val_dice_loss: 0.3138\n\nEpoch 00019: val_iou_coeff did not improve from 0.00128\nEpoch 20/32\n300/300 [==============================] - 161s 537ms/step - loss: 17378.5608 - acc: 0.9937 - recall: 0.6730 - precision: 0.8312 - iou_coeff: 0.5876 - dice_loss: 0.2709 - val_loss: 19510.1582 - val_acc: 0.9929 - val_recall: 0.6236 - val_precision: 0.8238 - val_iou_coeff: 0.5378 - val_dice_loss: 0.3124\n\nEpoch 00020: val_iou_coeff did not improve from 0.00128\nEpoch 21/32\n300/300 [==============================] - 161s 537ms/step - loss: 16988.6143 - acc: 0.9939 - recall: 0.6737 - precision: 0.8188 - iou_coeff: 0.5792 - dice_loss: 0.2780 - val_loss: 18843.0762 - val_acc: 0.9932 - val_recall: 0.6394 - val_precision: 0.8042 - val_iou_coeff: 0.5426 - val_dice_loss: 0.3128\n\nEpoch 00021: val_iou_coeff did not improve from 0.00128\nEpoch 22/32\n300/300 [==============================] - 161s 537ms/step - loss: 17844.1313 - acc: 0.9935 - recall: 0.6536 - precision: 0.8202 - iou_coeff: 0.5681 - dice_loss: 0.2877 - val_loss: 18163.2969 - val_acc: 0.9934 - val_recall: 0.6330 - val_precision: 0.8423 - val_iou_coeff: 0.5574 - val_dice_loss: 0.2973\n\nEpoch 00022: val_iou_coeff did not improve from 0.00128\nEpoch 23/32\n300/300 [==============================] - 161s 536ms/step - loss: 18117.3479 - acc: 0.9934 - recall: 0.6573 - precision: 0.8098 - iou_coeff: 0.5646 - dice_loss: 0.2896 - val_loss: 19109.7422 - val_acc: 0.9931 - val_recall: 0.6371 - val_precision: 0.8049 - val_iou_coeff: 0.5427 - val_dice_loss: 0.3127\n\nEpoch 00023: val_iou_coeff did not improve from 0.00128\nEpoch 24/32\n300/300 [==============================] - 161s 538ms/step - loss: 18605.8553 - acc: 0.9933 - recall: 0.6556 - precision: 0.8104 - iou_coeff: 0.5641 - dice_loss: 0.2914 - val_loss: 18827.8184 - val_acc: 0.9932 - val_recall: 0.6315 - val_precision: 0.7915 - val_iou_coeff: 0.5396 - val_dice_loss: 0.3177\n\nEpoch 00024: val_iou_coeff did not improve from 0.00128\nEpoch 25/32\n300/300 [==============================] - 161s 537ms/step - loss: 17610.0486 - acc: 0.9936 - recall: 0.6668 - precision: 0.8091 - iou_coeff: 0.5748 - dice_loss: 0.2833 - val_loss: 19206.3203 - val_acc: 0.9930 - val_recall: 0.6153 - val_precision: 0.8207 - val_iou_coeff: 0.5385 - val_dice_loss: 0.3186\n\nEpoch 00025: val_iou_coeff did not improve from 0.00128\nEpoch 26/32\n 48/300 [===>..........................] - ETA: 2:02 - loss: 15858.4496 - acc: 0.9943 - recall: 0.6755 - precision: 0.8558 - iou_coeff: 0.6019 - dice_loss: 0.2577","output_type":"stream"}]},{"cell_type":"code","source":"test_path = '../input/testdata/Test'\ntest_image_folder =\"images\"\nTest_path = test_path + '/' + 'test_image_folder'\ntest_label_folder =\"label\"\n\n\ndp = data_preprocess(train_path=train_path,image_folder=image_folder,label_folder=label_folder,\n                     valid_path=valid_path,valid_image_folder=valid_image_folder,valid_label_folder=valid_label_folder,\n                     flag_multi_class=flag_multi_class,\n                     num_classes=num_classes , test_path = Test_path , save_path = './' )\n\ntest_data = dp.testGenerator()\n\nimport os\n  \n# Directory\ndirectory = \"RESULT_R2NET\"\n  \n# Parent Directory path\nparent_dir = \"./\"\n  \n# Path\npath = os.path.join(parent_dir, directory)\nos.mkdir(path)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef read_image(path):\n    x = cv2.imread(path, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (512, 512))\n    x = x/255.0\n    return x\n\ndef read_mask(path):\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, ( 512 , 512))\n    x = np.expand_dims(x, axis=-1)\n    return x\n\ndef mask_parse(mask):\n    mask = np.squeeze(mask)\n    mask = [mask, mask, mask]\n    mask = np.transpose(mask, (1, 2, 0))\n    return mask\n\n\n\n\ndef tf_parse(imagepath , maskpath):\n  def _parse(imagepath , maskpath):\n    x = read_image(imagepath)\n    y = read_mask(maskpath)\n\n    return x , y\n\n  x , y = tf.numpy_function(_parse , [imagepath , maskpath] , [tf.float64 , tf.float64] )\n  x.set_shape([512 , 512 , 3])\n  y.set_shape([512, 512, 1])\n\n  return x , y \n\n\ndef tf_dataset( imagepath , maskpath , batch = 2):\n  dataset = tf.data.Dataset.from_tensor_slices((imagepath , maskpath))\n  dataset = dataset.map(tf_parse)\n  dataset = dataset.batch(batch)\n  dataset = dataset.repeat()\n  return dataset\n\n\nif __name__ == \"__main__\":\n    ## Dataset\n    \n    batch_size = 8\n    #(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(\"/content/drive/MyDrive/Test\")\n    test_x = os.listdir(os.path.join(test_path ,test_image_folder ))\n    test_y = os.listdir(os.path.join(test_path ,test_label_folder ))\n    \n    test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\n\n    test_steps = (len(test_x)//batch_size)\n    if len(test_x) % batch_size != 0:\n        test_steps += 1\n\n    #with CustomObjectScope({'iou': iou}):\n    #    model = tf.keras.models.load_model(\"/content/drive/model.h5\")\n\n    #model.evaluate(test_dataset, steps=test_steps)\n\n    for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n        x = read_image(x)\n        y = read_mask(y)\n        y_pred = model.predict(np.expand_dims(x, axis=0))[0] > 0.5\n        h, w, _ = x.shape\n        white_line = np.ones((h, 10, 3)) * 255.0\n\n        all_images = [\n            x * 255.0, white_line,\n            mask_parse(y), white_line,\n            mask_parse(y_pred) * 255.0\n        ]\n        image = np.concatenate(all_images, axis=1)\n        \n        cv2.imwrite(f\"./RESULT_DenseNet210WithDropout/{i}.png\", image)","metadata":{},"execution_count":null,"outputs":[]}]}