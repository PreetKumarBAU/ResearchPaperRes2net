{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n    add, multiply\nfrom keras.layers import concatenate, core, Dropout\nfrom keras.models import Model\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom keras.layers.core import Lambda\nimport keras.backend as K\n\n\n\n\ndef up_and_concate(down_layer, layer, data_format='channels_first'):\n    if data_format == 'channels_first':\n        in_channel = down_layer.get_shape().as_list()[1]\n    else:\n        in_channel = down_layer.get_shape().as_list()[3]\n\n    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n\n    if data_format == 'channels_first':\n        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n    else:\n        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n\n    concate = my_concat([up, layer])\n\n    return concate\n\n\ndef attention_up_and_concate(down_layer, layer, data_format='channels_first'):\n    if data_format == 'channels_first':\n        in_channel = down_layer.get_shape().as_list()[1]\n    else:\n        in_channel = down_layer.get_shape().as_list()[3]\n\n    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n\n    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n\n    if data_format == 'channels_first':\n        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n    else:\n        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n\n    concate = my_concat([up, layer])\n    return concate\n\n\ndef attention_block_2d(x, g, inter_channel, data_format='channels_first'):\n    # theta_x(?,g_height,g_width,inter_channel)\n\n    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n\n    # phi_g(?,g_height,g_width,inter_channel)\n\n    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n\n    # f(?,g_height,g_width,inter_channel)\n\n    f = Activation('relu')(add([theta_x, phi_g]))\n\n    # psi_f(?,g_height,g_width,1)\n\n    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n\n    rate = Activation('sigmoid')(psi_f)\n\n    # rate(?,x_height,x_width)\n\n    # att_x(?,x_height,x_width,x_channel)\n\n    att_x = multiply([x, rate])\n\n    return att_x\n\n\ndef res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n\n              padding='same', data_format='channels_first'):\n    if data_format == 'channels_first':\n        input_n_filters = input_layer.get_shape().as_list()[1]\n    else:\n        input_n_filters = input_layer.get_shape().as_list()[3]\n\n    layer = input_layer\n    for i in range(2):\n        layer = Conv2D(out_n_filters // 4, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n        if batch_normalization:\n            layer = BatchNormalization()(layer)\n        layer = Activation('relu')(layer)\n        layer = Conv2D(out_n_filters // 4, kernel_size, strides=stride, padding=padding, data_format=data_format)(layer)\n        layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n\n    if out_n_filters != input_n_filters:\n        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n            input_layer)\n    else:\n        skip_layer = input_layer\n    out_layer = add([layer, skip_layer])\n    return out_layer\n\n\n# Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\ndef rec_res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n\n                  padding='same', data_format='channels_first'):\n    if data_format == 'channels_first':\n        input_n_filters = input_layer.get_shape().as_list()[1]\n    else:\n        input_n_filters = input_layer.get_shape().as_list()[3]\n\n    if out_n_filters != input_n_filters:\n        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n            input_layer)\n    else:\n        skip_layer = input_layer\n\n    layer = skip_layer\n    for j in range(2):\n\n        for i in range(2):\n            if i == 0:\n\n                layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n                    layer)\n                if batch_normalization:\n                    layer1 = BatchNormalization()(layer1)\n                layer1 = Activation('relu')(layer1)\n            layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n                add([layer1, layer]))\n            if batch_normalization:\n                layer1 = BatchNormalization()(layer1)\n            layer1 = Activation('relu')(layer1)\n        layer = layer1\n\n    out_layer = add([layer, skip_layer])\n    return out_layer\n\n########################################################################################################\n# Define the neural network\ndef unet(img_w, img_h, n_label, data_format='channels_first'):\n    inputs = Input((3, img_w, img_h))\n    x = inputs\n    depth = 4\n    features = 64\n    skips = []\n    for i in range(depth):\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        x = Dropout(0.2)(x)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        skips.append(x)\n        x = MaxPooling2D((2, 2), data_format= data_format)(x)\n        features = features * 2\n\n    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n    x = Dropout(0.2)(x)\n    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n\n    for i in reversed(range(depth)):\n        features = features // 2\n        # attention_up_and_concate(x,[skips[i])\n        x = UpSampling2D(size=(2, 2), data_format=data_format)(x)\n        x = concatenate([skips[i], x], axis=1)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        x = Dropout(0.2)(x)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n\n    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n    conv7 = core.Activation('sigmoid')(conv6)\n    model = Model(inputs=inputs, outputs=conv7)\n\n    #model.compile(optimizer=Adam(lr=1e-5), loss=[focal_loss()], metrics=['accuracy', dice_coef])\n    return model\n\n\n########################################################################################################\n#Attention U-Net\ndef att_unet(img_w, img_h, n_label, data_format='channels_first'):\n    inputs = Input((3, img_w, img_h))\n    x = inputs\n    depth = 4\n    features = 64\n    skips = []\n    for i in range(depth):\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        x = Dropout(0.2)(x)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        skips.append(x)\n        x = MaxPooling2D((2, 2), data_format='channels_first')(x)\n        features = features * 2\n\n    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n    x = Dropout(0.2)(x)\n    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n\n    for i in reversed(range(depth)):\n        features = features // 2\n        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n        x = Dropout(0.2)(x)\n        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n\n    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n    conv7 = core.Activation('sigmoid')(conv6)\n    model = Model(inputs=inputs, outputs=conv7)\n\n    #model.compile(optimizer=Adam(lr=1e-5), loss=[focal_loss()], metrics=['accuracy', dice_coef])\n    return model\n\n\n########################################################################################################\n#Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\ndef r2_unet(img_w, img_h, n_label, data_format='channels_first'):\n    inputs = Input((3, img_w, img_h))\n    x = inputs\n    depth = 4\n    features = 64\n    skips = []\n    for i in range(depth):\n        x = rec_res_block(x, features, data_format=data_format)\n        skips.append(x)\n        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n\n        features = features * 2\n\n    x = rec_res_block(x, features, data_format=data_format)\n\n    for i in reversed(range(depth)):\n        features = features // 2\n        x = up_and_concate(x, skips[i], data_format=data_format)\n        x = rec_res_block(x, features, data_format=data_format)\n\n    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n    conv7 = core.Activation('sigmoid')(conv6)\n    model = Model(inputs=inputs, outputs=conv7)\n    #model.compile(optimizer=Adam(lr=1e-6), loss=[dice_coef_loss], metrics=['accuracy', dice_coef])\n    return model\n\n\n########################################################################################################\n#Attention R2U-Net\ndef att_r2_unet(img_w, img_h, n_label, data_format='channels_last'):\n    inputs = Input((img_w, img_h , 3))\n    x = inputs\n    depth = 4\n    features = 64\n    skips = []\n    for i in range(depth):\n        x = rec_res_block(x, features, data_format=data_format)\n        skips.append(x)\n        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n\n        features = features * 2\n\n    x = rec_res_block(x, features, data_format=data_format)\n\n    for i in reversed(range(depth)):\n        features = features // 2\n        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n        x = rec_res_block(x, features, data_format=data_format)\n\n    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n    conv7 = core.Activation('sigmoid')(conv6)\n    model = Model(inputs=inputs, outputs=conv7)\n    #model.compile(optimizer=Adam(lr=1e-6), loss=[dice_coef_loss], metrics=['accuracy', dice_coef])\n    return model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-26T14:20:12.035137Z","iopub.execute_input":"2021-07-26T14:20:12.035511Z","iopub.status.idle":"2021-07-26T14:20:12.082308Z","shell.execute_reply.started":"2021-07-26T14:20:12.035475Z","shell.execute_reply":"2021-07-26T14:20:12.081470Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"code","source":"\nimport os\nimport numpy as np\nfrom glob import glob\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:20:12.083652Z","iopub.execute_input":"2021-07-26T14:20:12.083994Z","iopub.status.idle":"2021-07-26T14:20:12.100635Z","shell.execute_reply.started":"2021-07-26T14:20:12.083961Z","shell.execute_reply":"2021-07-26T14:20:12.099832Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport numpy as np\nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport cv2\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nBackGround = [255, 255, 255]\nroad = [0, 0, 0]\n# COLOR_DICT = np.array([BackGround, road])\none = [128, 128, 128]\ntwo = [128, 0, 0]\nthree = [192, 192, 128]\nfour = [255, 69, 0]\nfive = [128, 64, 128]\nsix = [60, 40, 222]\nseven = [128, 128, 0]\neight = [192, 128, 128]\nnine = [64, 64, 128]\nten = [64, 0, 128]\neleven = [64, 64, 0]\ntwelve = [0, 128, 192]\nCOLOR_DICT = np.array([one, two,three,four,five,six,seven,eight,nine,ten,eleven,twelve])\n\n\nclass data_preprocess:\n    def __init__(self, train_path=None, image_folder=None, label_folder=None,\n                 valid_path=None,valid_image_folder =None,valid_label_folder = None,\n                 test_path=None, save_path=None,\n                 img_rows=512, img_cols=512,\n                 flag_multi_class=False,\n                 num_classes = 2):\n        self.img_rows = img_rows\n        self.img_cols = img_cols\n        self.train_path = train_path\n        self.image_folder = image_folder\n        self.label_folder = label_folder\n        self.valid_path = valid_path\n        self.valid_image_folder = valid_image_folder\n        self.valid_label_folder = valid_label_folder\n        self.test_path = test_path\n        self.save_path = save_path\n        self.data_gen_args = dict(rotation_range=50,\n                                  vertical_flip=True,\n                                  horizontal_flip=True,\n                                  fill_mode='nearest')\n        self.image_color_mode = \"rgb\"\n        self.label_color_mode = \"grayscale\"\n\n        self.flag_multi_class = flag_multi_class\n        self.num_class = num_classes\n        self.target_size = (img_cols, img_rows)\n        self.img_type = 'png'\n\n    def adjustData(self, img, label):\n        if (self.flag_multi_class):\n            img = img / 255.\n            label = label[:, :, :, 0] if (len(label.shape) == 4) else label[:, :, 0]\n            new_label = np.zeros(label.shape + (self.num_class,))\n            for i in range(self.num_class):\n                new_label[label == i, i] = 1\n            label = new_label\n        elif (np.max(img) > 1):\n            #img = img / 255.\n            #label = label / 255.\n            #label[label >= 0.5] = 1\n            #label[label < 0.5] = 0\n            img2 =np.asarray(img)\n            label2 =np.asarray(label)\n            img2 =img2.astype('float32')\n            label2 =label2.astype('float32')\n            img2 /= 255.0\n            label2 /= 255.0\n            label2[label2 >= 0.5] = 1\n            label2[label2 < 0.5] = 0\n        return (img2, label2)\n\n    def trainGenerator(self, batch_size, image_save_prefix=\"image\", label_save_prefix=\"label\",\n                       save_to_dir=None, seed=7):\n        '''\n        can generate image and label at the same time\n        use the same seed for image_datagen and label_datagen to ensure the transformation for image and label is the same\n        if you want to visualize the results of generator, set save_to_dir = \"your path\"\n        '''\n        image_datagen = ImageDataGenerator(**self.data_gen_args)\n        label_datagen = ImageDataGenerator(**self.data_gen_args)\n        image_generator = image_datagen.flow_from_directory(\n            self.train_path,\n            classes=[self.image_folder],\n            class_mode=None,\n            color_mode=self.image_color_mode,\n            target_size=self.target_size,\n            batch_size=batch_size,\n            save_to_dir=save_to_dir,\n            save_prefix=image_save_prefix,\n            seed=seed)\n        label_generator = label_datagen.flow_from_directory(\n            self.train_path,\n            classes=[self.label_folder],\n            class_mode=None,\n            color_mode=self.label_color_mode,\n            target_size=self.target_size,\n            batch_size=batch_size,\n            save_to_dir=save_to_dir,\n            save_prefix=label_save_prefix,\n            seed=seed)\n        train_generator = zip(image_generator, label_generator)\n        for (img, label) in train_generator:\n            img, label = self.adjustData(img, label)\n            yield (img, label)\n\n    def testGenerator(self):#no es usado por el momento\n        filenames = os.listdir(self.test_path)\n        for filename in filenames:\n            img = io.imread(os.path.join(self.test_path, filename), as_gray=False)\n            img = img / 255.\n            img = trans.resize(img, self.target_size, mode='constant')\n            img = np.reshape(img, img.shape + (1,)) if (not self.flag_multi_class) else img\n            img = np.reshape(img, (1,) + img.shape)\n            yield img\n\n    def validLoad(self, batch_size,seed=7):\n        image_datagen = ImageDataGenerator(rescale=0)\n        label_datagen = ImageDataGenerator(rescale=0)\n        image_generator = image_datagen.flow_from_directory(\n            self.valid_path,\n            classes=[self.valid_image_folder],\n            class_mode=None,\n            color_mode=self.image_color_mode,\n            target_size=self.target_size,\n            batch_size=batch_size,\n            seed=seed)\n        label_generator = label_datagen.flow_from_directory(\n            self.valid_path,\n            classes=[self.valid_label_folder],\n            class_mode=None,\n            color_mode=self.label_color_mode,\n            target_size=self.target_size,\n            batch_size=batch_size,\n            seed=seed)        \n        train_generator = zip(image_generator, label_generator)\n        for (img, label) in train_generator:\n            img, label = self.adjustData(img, label)\n            yield (img, label)\n        \n        # return imgs,labels\n\n    def saveResult(self, npyfile, size, name,threshold=80):#version alterna para guardar las predicciones\n        for i, item in enumerate(npyfile):\n            img = item\n            img_std = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n            if self.flag_multi_class:\n                for row in range(len(img)):\n                    for col in range(len(img[row])):\n                        num = np.argmax(img[row][col])\n                        img_std[row][col] = COLOR_DICT[num]\n            else:\n                for k in range(len(img)):\n                    for j in range(len(img[k])):\n                        num = img[k][j]\n                        if num < (threshold/255.0):\n                            img_std[k][j] = road\n                        else:\n                            img_std[k][j] = BackGround\n            img_std = cv2.resize(img_std, size, interpolation=cv2.INTER_CUBIC)\n            cv2.imwrite(os.path.join(self.save_path, (\"%s_predict.\" + self.img_type) % (name)), img_std)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:20:12.293620Z","iopub.execute_input":"2021-07-26T14:20:12.293886Z","iopub.status.idle":"2021-07-26T14:20:12.324232Z","shell.execute_reply.started":"2021-07-26T14:20:12.293852Z","shell.execute_reply":"2021-07-26T14:20:12.323160Z"},"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"code","source":"from keras import backend as K\nfrom keras.losses import binary_crossentropy\nimport tensorflow as tf\nimport numpy as np\ndef dice_coeff(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return score\ndef dice_loss(y_true, y_pred):\n    loss = 1 - dice_coeff(y_true, y_pred)\n    return loss\ndef iou_coeff(y_true, y_pred):\n    smooth=1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    union=K.sum(y_true_f) + K.sum(y_pred_f)-intersection\n    mvalue=(intersection+smooth)/(union+smooth)\n    return mvalue\ndef precision(y_true, y_pred):\n    \"\"\"Precision metric.\n    Only computes a batch-wise average of precision.\n    Computes the precision, a metric for multi-label classification of\n    how many selected items are relevant.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\ndef recall(y_true, y_pred):\n        \"\"\"Recall metric.\n        Only computes a batch-wise average of recall.\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\ndef ACL5(y_true, y_pred): \n\n\t#y_pred = K.cast(y_pred, dtype = 'float64')\n\n\tprint(K.int_shape(y_pred))\n\n\tx = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:] # horizontal and vertical directions \n\ty = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n\n\tdelta_x = x[:,1:,:-2,:]**2\n\tdelta_y = y[:,:-2,1:,:]**2\n\tdelta_u = K.abs(delta_x + delta_y) \n\n\tepsilon = 0.00000001 # where is a parameter to avoid square root is zero in practice.\n\tw = 1####\n\tlenth = w * K.sum(K.sqrt(delta_u + epsilon)) # equ.(11) in the paper\n\n\n\tC_1 = np.ones((512, 512))\n\tC_2 = np.zeros((512, 512))\n\n\tregion_in = K.abs(K.sum( y_pred[:,:,:,0] * ((y_true[:,:,:,0] - C_1)**2) ) ) # equ.(12) in the paper\n\tregion_out = K.abs(K.sum( (1-y_pred[:,:,:,0]) * ((y_true[:,:,:,0] - C_2)**2) )) # equ.(12) in the paper\n\n\tlambdaP = 5 # lambda parameter could be various.\n\t\n\tloss =  lenth + lambdaP * ((region_in) + (region_out)) \n\n\treturn loss","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:20:12.325788Z","iopub.execute_input":"2021-07-26T14:20:12.326135Z","iopub.status.idle":"2021-07-26T14:20:12.344468Z","shell.execute_reply.started":"2021-07-26T14:20:12.326099Z","shell.execute_reply":"2021-07-26T14:20:12.343585Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport keras\nfrom keras.callbacks import TensorBoard\nimport tensorflow as tf\n#import keras.backend.tensorflow_backend as K\nimport matplotlib.pyplot as plt\nfrom keras.callbacks import CSVLogger\n\nnp.random.seed(42)\ntf.random.set_seed(42)\n    \n#config = tf.ConfigProto()\n#config.gpu_options.allow_growth=True\n#sess = tf.Session(config=config)\n#K.set_session(sess)\n #os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\n\n#path to images which are prepared to train a model\ntrain_path = \"../input/training/training\"\nimage_folder = \"images\"\nlabel_folder = \"label\"\nvalid_path =  \"../input/validation/Validation\"\nvalid_image_folder =\"images\"\nvalid_label_folder = \"label\"\nlog_filepath = './log'\nflag_multi_class = False\nnum_classes = 2\nlr = 8.00E-05\nbatch = 2\n\n\n\nopt = tf.keras.optimizers.Adam(lr , beta_1=0.9,\n    beta_2=0.999)\n\ndp = data_preprocess(train_path=train_path,image_folder=image_folder,label_folder=label_folder,\n                     valid_path=valid_path,valid_image_folder=valid_image_folder,valid_label_folder=valid_label_folder,\n                     flag_multi_class=flag_multi_class,\n                     num_classes=num_classes)\n\ntrain_data = dp.trainGenerator(batch_size=2)\nvalid_data = dp.validLoad(batch_size=2)\n#Number Of Batches\n#rain_steps = len(train_data)//batch\n#valid_steps = len(valid_data)//batch\n\n\n#if len(train_data) % batch != 0:\n#        train_steps += 1\n#if len(valid_data) % batch != 0:\n#        valid_steps += 1\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:20:12.346552Z","iopub.execute_input":"2021-07-26T14:20:12.346907Z","iopub.status.idle":"2021-07-26T14:20:12.385831Z","shell.execute_reply.started":"2021-07-26T14:20:12.346873Z","shell.execute_reply":"2021-07-26T14:20:12.385024Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"\nbeta = 0.25\nalpha = 0.25\ngamma = 2\nepsilon = 1e-5\nsmooth = 1\n\ndef tversky_index( y_true, y_pred):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n    alpha = 0.7\n    return (true_pos + smooth) / (true_pos + alpha * false_neg + (\n                1 - alpha) * false_pos + smooth)\n\ndef tversky_loss( y_true, y_pred):\n    return 1 - tversky_index(y_true, y_pred)\n\ndef focal_tversky( y_true, y_pred):\n    pt_1 = tversky_index(y_true, y_pred)\n    gamma = 0.75\n    return K.pow((1 - pt_1), gamma)\n\ndef dsc(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return score\n\ndef dice_loss(y_true, y_pred):\n    loss = 1 - dsc(y_true, y_pred)\n    return loss\n\ndef bce_dice_loss(y_true, y_pred):\n    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:20:12.387655Z","iopub.execute_input":"2021-07-26T14:20:12.388003Z","iopub.status.idle":"2021-07-26T14:20:12.399315Z","shell.execute_reply.started":"2021-07-26T14:20:12.387965Z","shell.execute_reply":"2021-07-26T14:20:12.398554Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import *\nfrom keras.layers import Input, Conv2D, UpSampling2D, BatchNormalization, Activation, add,average,concatenate\nfrom keras.layers.core import Lambda\nfrom keras.optimizers import *\nfrom keras.losses import binary_crossentropy\n\n\n\nIMG_SIZE = 512\nh_heuns_method=0.5\n\ndef res_block(x, nb_filters, strides):\n    res_path = BatchNormalization()(x)\n    res_path = Activation(activation='relu')(res_path)\n    res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same' ,strides=strides[0])(res_path)\n\n    res_path = BatchNormalization()(res_path)\n    res_path = Activation(activation='relu')(res_path)\n    res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same',strides=strides[1])(res_path)\n    hpath = Lambda(lambda x: x * h_heuns_method)(res_path)\n\n    shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1),strides=strides[0])(x)\n    shortcut = BatchNormalization()(shortcut)\n\n    res_path = add([shortcut, hpath])#suma corta\n    return res_path\ndef res_block2(x,y,nb_filters, strides):\n    res_path = BatchNormalization()(x)\n    res_path = Activation(activation='relu')(res_path)\n    res_path = Conv2D(filters=nb_filters[0], kernel_size=(3, 3), padding='same' ,strides=strides[0])(res_path)\n\n    res_path = BatchNormalization()(res_path)\n    res_path = Activation(activation='relu')(res_path)\n    res_path = Conv2D(filters=nb_filters[1], kernel_size=(3, 3), padding='same',strides=strides[1])(res_path)\n    hpath = Lambda(lambda x: x * h_heuns_method)(res_path)\n\n    shortcut = Conv2D(nb_filters[1], kernel_size=(1, 1),strides=strides[0])(x)\n    shortcut = BatchNormalization()(shortcut)\n\n    res_path = add([shortcut, hpath])#suma corta\n\n    res_path = average([y, res_path])#suma doble \n    return res_path\n\n\ndef encoder(x):\n    to_decoder = []\n\n    main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1))(x)\n    main_path = BatchNormalization()(main_path)\n    main_path = Activation(activation='relu')(main_path)\n\n    main_path = Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1))(main_path)\n    hpath = Lambda(lambda x: x * h_heuns_method)(main_path)\n\n    shortcut = Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1))(x)\n    shortcut = BatchNormalization()(shortcut)\n\n    main_path = add([shortcut, hpath])#suma corta\n\n    to_decoder.append(main_path)\n\n\n    s1 = Conv2D(filters=128, kernel_size=(1, 1), strides=(2, 2))(x)\n    s1 = BatchNormalization()(s1)\n\n    main_path = res_block2(main_path,s1, [128, 128], [(2, 2), (1, 1)]) \n    to_decoder.append(main_path)\n\n    main_path = res_block(main_path, [256, 256], [(2, 2), (1, 1)])\n    to_decoder.append(main_path)\n\n    s2 = Conv2D(filters=512, kernel_size=(1, 1), strides=(4, 4))(to_decoder[1])\n    s2 = BatchNormalization()(s2)\n\n    main_path = res_block2(main_path,s2, [512, 512], [(2, 2), (1, 1)])\n    to_decoder.append(main_path)\n\n    return to_decoder\n\n\ndef decoder(x, from_encoder):\n    main_path = UpSampling2D(size=(2, 2))(x)#32x32\n    main_path1 = concatenate([main_path, from_encoder[3]], axis=3)\n    main_path = res_block(main_path1, [512, 512], [(1, 1), (1, 1)])\n\n    main_path = UpSampling2D(size=(2, 2))(main_path)###64x64\n    main_path = concatenate([main_path, from_encoder[2]], axis=3)#\n    u1 = UpSampling2D(size=(2, 2))(main_path1)#\n    u1 = Conv2D(256, kernel_size=(1, 1),strides=(1, 1))(u1)\n    u1 = BatchNormalization()(u1)\n    main_path = res_block2(main_path,u1, [256, 256], [(1, 1), (1, 1)])#\n\n    main_path = UpSampling2D(size=(2, 2))(main_path)#128x128\n    main_path2 = concatenate([main_path, from_encoder[1]], axis=3)#\n    main_path = res_block(main_path2, [128, 128], [(1, 1), (1, 1)])#\n\n    main_path = UpSampling2D(size=(2, 2))(main_path)#256x256\n    main_path = concatenate([main_path, from_encoder[0]], axis=3)#256x256\n\n    u2 = UpSampling2D(size=(2,2))(main_path2)#\n    u2 = Conv2D(64, kernel_size=(1, 1),strides=(1, 1))(u2)#\n    u2 = BatchNormalization()(u2)\n    main_path = res_block2(main_path,u2, [64, 64], [(1, 1), (1, 1)])#256x256\n\n    return main_path\n\n\ndef res2unet(lrate=8.00E-05,pretrained_weights=None):\n    print(lrate)\n    input_size=(512, 512, 3)\n    inputs = Input(shape=input_size)\n\n    to_decoder = encoder(inputs)\n\n    path = res_block(to_decoder[3], [1024, 1024], [(2, 2), (1, 1)])####bridge\n\n    path = decoder(path, from_encoder=to_decoder)\n\n\n    path = Conv2D(2, kernel_size=(3, 3),activation='relu', padding='same', strides=(1, 1))(path)\n    path = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(path)\n    model = Model(inputs=inputs, outputs=path)\n    #model.compile(optimizer=Adam(lr=lrate), loss=ACL5, metrics=[dice_loss,iou_coeff,precision,recall])\n    #model.summary()\n    if (pretrained_weights):\n        model.load_weights(pretrained_weights)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:20:12.400872Z","iopub.execute_input":"2021-07-26T14:20:12.401308Z","iopub.status.idle":"2021-07-26T14:20:12.431927Z","shell.execute_reply.started":"2021-07-26T14:20:12.401271Z","shell.execute_reply":"2021-07-26T14:20:12.431044Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"%env SM_FRAMEWORK=tf.keras","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:20:12.433120Z","iopub.execute_input":"2021-07-26T14:20:12.433499Z","iopub.status.idle":"2021-07-26T14:20:12.446745Z","shell.execute_reply.started":"2021-07-26T14:20:12.433464Z","shell.execute_reply":"2021-07-26T14:20:12.445916Z"},"trusted":true},"execution_count":192,"outputs":[{"name":"stdout","text":"env: SM_FRAMEWORK=tf.keras\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install segmentation_models\nimport segmentation_models\nfrom segmentation_models.losses import bce_jaccard_loss","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:20:12.447723Z","iopub.execute_input":"2021-07-26T14:20:12.447983Z","iopub.status.idle":"2021-07-26T14:20:19.161227Z","shell.execute_reply.started":"2021-07-26T14:20:12.447960Z","shell.execute_reply":"2021-07-26T14:20:19.160297Z"},"trusted":true},"execution_count":193,"outputs":[{"name":"stdout","text":"Requirement already satisfied: segmentation_models in /opt/conda/lib/python3.7/site-packages (1.0.1)\nRequirement already satisfied: efficientnet==1.0.0 in /opt/conda/lib/python3.7/site-packages (from segmentation_models) (1.0.0)\nRequirement already satisfied: image-classifiers==1.0.0 in /opt/conda/lib/python3.7/site-packages (from segmentation_models) (1.0.0)\nRequirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from segmentation_models) (1.0.8)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation_models) (0.18.2)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.10.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.19.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.15.0)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.9.0)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5)\nRequirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.6.3)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.4.2)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (8.2.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.7.2)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.1)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.7)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (5.0.9)\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"def ACL5_bce_jaccard_loss(y_true, y_pred):\n    loss = ACL5(y_true, y_pred) + 1.75*bce_jaccard_loss(y_true, y_pred)\n    return loss\n\n\ndef focal_tversky_bce_jaccard_loss(y_true, y_pred):\n    loss = focal_tversky(y_true, y_pred) + 2*bce_jaccard_loss(y_true, y_pred)\n    return loss\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:20:19.164505Z","iopub.execute_input":"2021-07-26T14:20:19.164782Z","iopub.status.idle":"2021-07-26T14:20:19.169393Z","shell.execute_reply.started":"2021-07-26T14:20:19.164754Z","shell.execute_reply":"2021-07-26T14:20:19.168587Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nimg_w  , img_h = 512 , 512\nn_label = 1\n#model =res2unet(lrate=8.00E-04,pretrained_weights=None)\n#model = unet(lrate=1e-4,ls=2)# WBCE\nmodel = att_r2_unet(img_w, img_h, n_label, data_format='channels_last')\nmetrics = [\"acc\" , recall , precision  , iou_coeff ,dice_loss]\nmodel_checkpoint1 = keras.callbacks.ModelCheckpoint('Res2Net.hdf5', monitor= 'val_iou_coeff' ,verbose=1,mode='min',save_best_only=True)#para guardar el entranamiento con menor dice loss en validation\n#steps_per_epochnumber= 600 / 2\n#validation_stepsnumber = 200 / 2\n\ncsv_logger = CSVLogger('trainingRes2Net.log', append=True, separator=';')#respaldo de datos de entranamiento \nmodel.compile(optimizer= opt, loss=focal_tversky_bce_jaccard_loss , metrics=[\"acc\" , recall , precision , iou_coeff ,dice_loss])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:20:19.172277Z","iopub.execute_input":"2021-07-26T14:20:19.172670Z","iopub.status.idle":"2021-07-26T14:20:20.097390Z","shell.execute_reply.started":"2021-07-26T14:20:19.172642Z","shell.execute_reply":"2021-07-26T14:20:20.091056Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":195,"outputs":[{"name":"stdout","text":"Model: \"model_13\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_21 (InputLayer)           [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d_1004 (Conv2D)            (None, 512, 512, 64) 256         input_21[0][0]                   \n__________________________________________________________________________________________________\nconv2d_1005 (Conv2D)            (None, 512, 512, 64) 36928       conv2d_1004[0][0]                \n__________________________________________________________________________________________________\nactivation_708 (Activation)     (None, 512, 512, 64) 0           conv2d_1005[0][0]                \n__________________________________________________________________________________________________\nadd_500 (Add)                   (None, 512, 512, 64) 0           activation_708[0][0]             \n                                                                 conv2d_1004[0][0]                \n__________________________________________________________________________________________________\nconv2d_1006 (Conv2D)            (None, 512, 512, 64) 36928       add_500[0][0]                    \n__________________________________________________________________________________________________\nactivation_709 (Activation)     (None, 512, 512, 64) 0           conv2d_1006[0][0]                \n__________________________________________________________________________________________________\nadd_501 (Add)                   (None, 512, 512, 64) 0           activation_709[0][0]             \n                                                                 conv2d_1004[0][0]                \n__________________________________________________________________________________________________\nconv2d_1007 (Conv2D)            (None, 512, 512, 64) 36928       add_501[0][0]                    \n__________________________________________________________________________________________________\nactivation_710 (Activation)     (None, 512, 512, 64) 0           conv2d_1007[0][0]                \n__________________________________________________________________________________________________\nconv2d_1008 (Conv2D)            (None, 512, 512, 64) 36928       activation_710[0][0]             \n__________________________________________________________________________________________________\nactivation_711 (Activation)     (None, 512, 512, 64) 0           conv2d_1008[0][0]                \n__________________________________________________________________________________________________\nadd_502 (Add)                   (None, 512, 512, 64) 0           activation_711[0][0]             \n                                                                 activation_710[0][0]             \n__________________________________________________________________________________________________\nconv2d_1009 (Conv2D)            (None, 512, 512, 64) 36928       add_502[0][0]                    \n__________________________________________________________________________________________________\nactivation_712 (Activation)     (None, 512, 512, 64) 0           conv2d_1009[0][0]                \n__________________________________________________________________________________________________\nadd_503 (Add)                   (None, 512, 512, 64) 0           activation_712[0][0]             \n                                                                 activation_710[0][0]             \n__________________________________________________________________________________________________\nconv2d_1010 (Conv2D)            (None, 512, 512, 64) 36928       add_503[0][0]                    \n__________________________________________________________________________________________________\nactivation_713 (Activation)     (None, 512, 512, 64) 0           conv2d_1010[0][0]                \n__________________________________________________________________________________________________\nadd_504 (Add)                   (None, 512, 512, 64) 0           activation_713[0][0]             \n                                                                 conv2d_1004[0][0]                \n__________________________________________________________________________________________________\nmax_pooling2d_32 (MaxPooling2D) (None, 256, 256, 64) 0           add_504[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1011 (Conv2D)            (None, 256, 256, 128 8320        max_pooling2d_32[0][0]           \n__________________________________________________________________________________________________\nconv2d_1012 (Conv2D)            (None, 256, 256, 128 147584      conv2d_1011[0][0]                \n__________________________________________________________________________________________________\nactivation_714 (Activation)     (None, 256, 256, 128 0           conv2d_1012[0][0]                \n__________________________________________________________________________________________________\nadd_505 (Add)                   (None, 256, 256, 128 0           activation_714[0][0]             \n                                                                 conv2d_1011[0][0]                \n__________________________________________________________________________________________________\nconv2d_1013 (Conv2D)            (None, 256, 256, 128 147584      add_505[0][0]                    \n__________________________________________________________________________________________________\nactivation_715 (Activation)     (None, 256, 256, 128 0           conv2d_1013[0][0]                \n__________________________________________________________________________________________________\nadd_506 (Add)                   (None, 256, 256, 128 0           activation_715[0][0]             \n                                                                 conv2d_1011[0][0]                \n__________________________________________________________________________________________________\nconv2d_1014 (Conv2D)            (None, 256, 256, 128 147584      add_506[0][0]                    \n__________________________________________________________________________________________________\nactivation_716 (Activation)     (None, 256, 256, 128 0           conv2d_1014[0][0]                \n__________________________________________________________________________________________________\nconv2d_1015 (Conv2D)            (None, 256, 256, 128 147584      activation_716[0][0]             \n__________________________________________________________________________________________________\nactivation_717 (Activation)     (None, 256, 256, 128 0           conv2d_1015[0][0]                \n__________________________________________________________________________________________________\nadd_507 (Add)                   (None, 256, 256, 128 0           activation_717[0][0]             \n                                                                 activation_716[0][0]             \n__________________________________________________________________________________________________\nconv2d_1016 (Conv2D)            (None, 256, 256, 128 147584      add_507[0][0]                    \n__________________________________________________________________________________________________\nactivation_718 (Activation)     (None, 256, 256, 128 0           conv2d_1016[0][0]                \n__________________________________________________________________________________________________\nadd_508 (Add)                   (None, 256, 256, 128 0           activation_718[0][0]             \n                                                                 activation_716[0][0]             \n__________________________________________________________________________________________________\nconv2d_1017 (Conv2D)            (None, 256, 256, 128 147584      add_508[0][0]                    \n__________________________________________________________________________________________________\nactivation_719 (Activation)     (None, 256, 256, 128 0           conv2d_1017[0][0]                \n__________________________________________________________________________________________________\nadd_509 (Add)                   (None, 256, 256, 128 0           activation_719[0][0]             \n                                                                 conv2d_1011[0][0]                \n__________________________________________________________________________________________________\nmax_pooling2d_33 (MaxPooling2D) (None, 128, 128, 128 0           add_509[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1018 (Conv2D)            (None, 128, 128, 256 33024       max_pooling2d_33[0][0]           \n__________________________________________________________________________________________________\nconv2d_1019 (Conv2D)            (None, 128, 128, 256 590080      conv2d_1018[0][0]                \n__________________________________________________________________________________________________\nactivation_720 (Activation)     (None, 128, 128, 256 0           conv2d_1019[0][0]                \n__________________________________________________________________________________________________\nadd_510 (Add)                   (None, 128, 128, 256 0           activation_720[0][0]             \n                                                                 conv2d_1018[0][0]                \n__________________________________________________________________________________________________\nconv2d_1020 (Conv2D)            (None, 128, 128, 256 590080      add_510[0][0]                    \n__________________________________________________________________________________________________\nactivation_721 (Activation)     (None, 128, 128, 256 0           conv2d_1020[0][0]                \n__________________________________________________________________________________________________\nadd_511 (Add)                   (None, 128, 128, 256 0           activation_721[0][0]             \n                                                                 conv2d_1018[0][0]                \n__________________________________________________________________________________________________\nconv2d_1021 (Conv2D)            (None, 128, 128, 256 590080      add_511[0][0]                    \n__________________________________________________________________________________________________\nactivation_722 (Activation)     (None, 128, 128, 256 0           conv2d_1021[0][0]                \n__________________________________________________________________________________________________\nconv2d_1022 (Conv2D)            (None, 128, 128, 256 590080      activation_722[0][0]             \n__________________________________________________________________________________________________\nactivation_723 (Activation)     (None, 128, 128, 256 0           conv2d_1022[0][0]                \n__________________________________________________________________________________________________\nadd_512 (Add)                   (None, 128, 128, 256 0           activation_723[0][0]             \n                                                                 activation_722[0][0]             \n__________________________________________________________________________________________________\nconv2d_1023 (Conv2D)            (None, 128, 128, 256 590080      add_512[0][0]                    \n__________________________________________________________________________________________________\nactivation_724 (Activation)     (None, 128, 128, 256 0           conv2d_1023[0][0]                \n__________________________________________________________________________________________________\nadd_513 (Add)                   (None, 128, 128, 256 0           activation_724[0][0]             \n                                                                 activation_722[0][0]             \n__________________________________________________________________________________________________\nconv2d_1024 (Conv2D)            (None, 128, 128, 256 590080      add_513[0][0]                    \n__________________________________________________________________________________________________\nactivation_725 (Activation)     (None, 128, 128, 256 0           conv2d_1024[0][0]                \n__________________________________________________________________________________________________\nadd_514 (Add)                   (None, 128, 128, 256 0           activation_725[0][0]             \n                                                                 conv2d_1018[0][0]                \n__________________________________________________________________________________________________\nmax_pooling2d_34 (MaxPooling2D) (None, 64, 64, 256)  0           add_514[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1025 (Conv2D)            (None, 64, 64, 512)  131584      max_pooling2d_34[0][0]           \n__________________________________________________________________________________________________\nconv2d_1026 (Conv2D)            (None, 64, 64, 512)  2359808     conv2d_1025[0][0]                \n__________________________________________________________________________________________________\nactivation_726 (Activation)     (None, 64, 64, 512)  0           conv2d_1026[0][0]                \n__________________________________________________________________________________________________\nadd_515 (Add)                   (None, 64, 64, 512)  0           activation_726[0][0]             \n                                                                 conv2d_1025[0][0]                \n__________________________________________________________________________________________________\nconv2d_1027 (Conv2D)            (None, 64, 64, 512)  2359808     add_515[0][0]                    \n__________________________________________________________________________________________________\nactivation_727 (Activation)     (None, 64, 64, 512)  0           conv2d_1027[0][0]                \n__________________________________________________________________________________________________\nadd_516 (Add)                   (None, 64, 64, 512)  0           activation_727[0][0]             \n                                                                 conv2d_1025[0][0]                \n__________________________________________________________________________________________________\nconv2d_1028 (Conv2D)            (None, 64, 64, 512)  2359808     add_516[0][0]                    \n__________________________________________________________________________________________________\nactivation_728 (Activation)     (None, 64, 64, 512)  0           conv2d_1028[0][0]                \n__________________________________________________________________________________________________\nconv2d_1029 (Conv2D)            (None, 64, 64, 512)  2359808     activation_728[0][0]             \n__________________________________________________________________________________________________\nactivation_729 (Activation)     (None, 64, 64, 512)  0           conv2d_1029[0][0]                \n__________________________________________________________________________________________________\nadd_517 (Add)                   (None, 64, 64, 512)  0           activation_729[0][0]             \n                                                                 activation_728[0][0]             \n__________________________________________________________________________________________________\nconv2d_1030 (Conv2D)            (None, 64, 64, 512)  2359808     add_517[0][0]                    \n__________________________________________________________________________________________________\nactivation_730 (Activation)     (None, 64, 64, 512)  0           conv2d_1030[0][0]                \n__________________________________________________________________________________________________\nadd_518 (Add)                   (None, 64, 64, 512)  0           activation_730[0][0]             \n                                                                 activation_728[0][0]             \n__________________________________________________________________________________________________\nconv2d_1031 (Conv2D)            (None, 64, 64, 512)  2359808     add_518[0][0]                    \n__________________________________________________________________________________________________\nactivation_731 (Activation)     (None, 64, 64, 512)  0           conv2d_1031[0][0]                \n__________________________________________________________________________________________________\nadd_519 (Add)                   (None, 64, 64, 512)  0           activation_731[0][0]             \n                                                                 conv2d_1025[0][0]                \n__________________________________________________________________________________________________\nmax_pooling2d_35 (MaxPooling2D) (None, 32, 32, 512)  0           add_519[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1032 (Conv2D)            (None, 32, 32, 1024) 525312      max_pooling2d_35[0][0]           \n__________________________________________________________________________________________________\nconv2d_1033 (Conv2D)            (None, 32, 32, 1024) 9438208     conv2d_1032[0][0]                \n__________________________________________________________________________________________________\nactivation_732 (Activation)     (None, 32, 32, 1024) 0           conv2d_1033[0][0]                \n__________________________________________________________________________________________________\nadd_520 (Add)                   (None, 32, 32, 1024) 0           activation_732[0][0]             \n                                                                 conv2d_1032[0][0]                \n__________________________________________________________________________________________________\nconv2d_1034 (Conv2D)            (None, 32, 32, 1024) 9438208     add_520[0][0]                    \n__________________________________________________________________________________________________\nactivation_733 (Activation)     (None, 32, 32, 1024) 0           conv2d_1034[0][0]                \n__________________________________________________________________________________________________\nadd_521 (Add)                   (None, 32, 32, 1024) 0           activation_733[0][0]             \n                                                                 conv2d_1032[0][0]                \n__________________________________________________________________________________________________\nconv2d_1035 (Conv2D)            (None, 32, 32, 1024) 9438208     add_521[0][0]                    \n__________________________________________________________________________________________________\nactivation_734 (Activation)     (None, 32, 32, 1024) 0           conv2d_1035[0][0]                \n__________________________________________________________________________________________________\nconv2d_1036 (Conv2D)            (None, 32, 32, 1024) 9438208     activation_734[0][0]             \n__________________________________________________________________________________________________\nactivation_735 (Activation)     (None, 32, 32, 1024) 0           conv2d_1036[0][0]                \n__________________________________________________________________________________________________\nadd_522 (Add)                   (None, 32, 32, 1024) 0           activation_735[0][0]             \n                                                                 activation_734[0][0]             \n__________________________________________________________________________________________________\nconv2d_1037 (Conv2D)            (None, 32, 32, 1024) 9438208     add_522[0][0]                    \n__________________________________________________________________________________________________\nactivation_736 (Activation)     (None, 32, 32, 1024) 0           conv2d_1037[0][0]                \n__________________________________________________________________________________________________\nadd_523 (Add)                   (None, 32, 32, 1024) 0           activation_736[0][0]             \n                                                                 activation_734[0][0]             \n__________________________________________________________________________________________________\nconv2d_1038 (Conv2D)            (None, 32, 32, 1024) 9438208     add_523[0][0]                    \n__________________________________________________________________________________________________\nactivation_737 (Activation)     (None, 32, 32, 1024) 0           conv2d_1038[0][0]                \n__________________________________________________________________________________________________\nadd_524 (Add)                   (None, 32, 32, 1024) 0           activation_737[0][0]             \n                                                                 conv2d_1032[0][0]                \n__________________________________________________________________________________________________\nup_sampling2d_104 (UpSampling2D (None, 64, 64, 1024) 0           add_524[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1039 (Conv2D)            (None, 64, 64, 256)  131328      add_519[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1040 (Conv2D)            (None, 64, 64, 256)  262400      up_sampling2d_104[0][0]          \n__________________________________________________________________________________________________\nadd_525 (Add)                   (None, 64, 64, 256)  0           conv2d_1039[0][0]                \n                                                                 conv2d_1040[0][0]                \n__________________________________________________________________________________________________\nactivation_738 (Activation)     (None, 64, 64, 256)  0           add_525[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1041 (Conv2D)            (None, 64, 64, 1)    257         activation_738[0][0]             \n__________________________________________________________________________________________________\nactivation_739 (Activation)     (None, 64, 64, 1)    0           conv2d_1041[0][0]                \n__________________________________________________________________________________________________\nmultiply_32 (Multiply)          (None, 64, 64, 512)  0           add_519[0][0]                    \n                                                                 activation_739[0][0]             \n__________________________________________________________________________________________________\nlambda_140 (Lambda)             (None, 64, 64, 1536) 0           up_sampling2d_104[0][0]          \n                                                                 multiply_32[0][0]                \n__________________________________________________________________________________________________\nconv2d_1042 (Conv2D)            (None, 64, 64, 512)  786944      lambda_140[0][0]                 \n__________________________________________________________________________________________________\nconv2d_1043 (Conv2D)            (None, 64, 64, 512)  2359808     conv2d_1042[0][0]                \n__________________________________________________________________________________________________\nactivation_740 (Activation)     (None, 64, 64, 512)  0           conv2d_1043[0][0]                \n__________________________________________________________________________________________________\nadd_526 (Add)                   (None, 64, 64, 512)  0           activation_740[0][0]             \n                                                                 conv2d_1042[0][0]                \n__________________________________________________________________________________________________\nconv2d_1044 (Conv2D)            (None, 64, 64, 512)  2359808     add_526[0][0]                    \n__________________________________________________________________________________________________\nactivation_741 (Activation)     (None, 64, 64, 512)  0           conv2d_1044[0][0]                \n__________________________________________________________________________________________________\nadd_527 (Add)                   (None, 64, 64, 512)  0           activation_741[0][0]             \n                                                                 conv2d_1042[0][0]                \n__________________________________________________________________________________________________\nconv2d_1045 (Conv2D)            (None, 64, 64, 512)  2359808     add_527[0][0]                    \n__________________________________________________________________________________________________\nactivation_742 (Activation)     (None, 64, 64, 512)  0           conv2d_1045[0][0]                \n__________________________________________________________________________________________________\nconv2d_1046 (Conv2D)            (None, 64, 64, 512)  2359808     activation_742[0][0]             \n__________________________________________________________________________________________________\nactivation_743 (Activation)     (None, 64, 64, 512)  0           conv2d_1046[0][0]                \n__________________________________________________________________________________________________\nadd_528 (Add)                   (None, 64, 64, 512)  0           activation_743[0][0]             \n                                                                 activation_742[0][0]             \n__________________________________________________________________________________________________\nconv2d_1047 (Conv2D)            (None, 64, 64, 512)  2359808     add_528[0][0]                    \n__________________________________________________________________________________________________\nactivation_744 (Activation)     (None, 64, 64, 512)  0           conv2d_1047[0][0]                \n__________________________________________________________________________________________________\nadd_529 (Add)                   (None, 64, 64, 512)  0           activation_744[0][0]             \n                                                                 activation_742[0][0]             \n__________________________________________________________________________________________________\nconv2d_1048 (Conv2D)            (None, 64, 64, 512)  2359808     add_529[0][0]                    \n__________________________________________________________________________________________________\nactivation_745 (Activation)     (None, 64, 64, 512)  0           conv2d_1048[0][0]                \n__________________________________________________________________________________________________\nadd_530 (Add)                   (None, 64, 64, 512)  0           activation_745[0][0]             \n                                                                 conv2d_1042[0][0]                \n__________________________________________________________________________________________________\nup_sampling2d_105 (UpSampling2D (None, 128, 128, 512 0           add_530[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1049 (Conv2D)            (None, 128, 128, 128 32896       add_514[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1050 (Conv2D)            (None, 128, 128, 128 65664       up_sampling2d_105[0][0]          \n__________________________________________________________________________________________________\nadd_531 (Add)                   (None, 128, 128, 128 0           conv2d_1049[0][0]                \n                                                                 conv2d_1050[0][0]                \n__________________________________________________________________________________________________\nactivation_746 (Activation)     (None, 128, 128, 128 0           add_531[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1051 (Conv2D)            (None, 128, 128, 1)  129         activation_746[0][0]             \n__________________________________________________________________________________________________\nactivation_747 (Activation)     (None, 128, 128, 1)  0           conv2d_1051[0][0]                \n__________________________________________________________________________________________________\nmultiply_33 (Multiply)          (None, 128, 128, 256 0           add_514[0][0]                    \n                                                                 activation_747[0][0]             \n__________________________________________________________________________________________________\nlambda_141 (Lambda)             (None, 128, 128, 768 0           up_sampling2d_105[0][0]          \n                                                                 multiply_33[0][0]                \n__________________________________________________________________________________________________\nconv2d_1052 (Conv2D)            (None, 128, 128, 256 196864      lambda_141[0][0]                 \n__________________________________________________________________________________________________\nconv2d_1053 (Conv2D)            (None, 128, 128, 256 590080      conv2d_1052[0][0]                \n__________________________________________________________________________________________________\nactivation_748 (Activation)     (None, 128, 128, 256 0           conv2d_1053[0][0]                \n__________________________________________________________________________________________________\nadd_532 (Add)                   (None, 128, 128, 256 0           activation_748[0][0]             \n                                                                 conv2d_1052[0][0]                \n__________________________________________________________________________________________________\nconv2d_1054 (Conv2D)            (None, 128, 128, 256 590080      add_532[0][0]                    \n__________________________________________________________________________________________________\nactivation_749 (Activation)     (None, 128, 128, 256 0           conv2d_1054[0][0]                \n__________________________________________________________________________________________________\nadd_533 (Add)                   (None, 128, 128, 256 0           activation_749[0][0]             \n                                                                 conv2d_1052[0][0]                \n__________________________________________________________________________________________________\nconv2d_1055 (Conv2D)            (None, 128, 128, 256 590080      add_533[0][0]                    \n__________________________________________________________________________________________________\nactivation_750 (Activation)     (None, 128, 128, 256 0           conv2d_1055[0][0]                \n__________________________________________________________________________________________________\nconv2d_1056 (Conv2D)            (None, 128, 128, 256 590080      activation_750[0][0]             \n__________________________________________________________________________________________________\nactivation_751 (Activation)     (None, 128, 128, 256 0           conv2d_1056[0][0]                \n__________________________________________________________________________________________________\nadd_534 (Add)                   (None, 128, 128, 256 0           activation_751[0][0]             \n                                                                 activation_750[0][0]             \n__________________________________________________________________________________________________\nconv2d_1057 (Conv2D)            (None, 128, 128, 256 590080      add_534[0][0]                    \n__________________________________________________________________________________________________\nactivation_752 (Activation)     (None, 128, 128, 256 0           conv2d_1057[0][0]                \n__________________________________________________________________________________________________\nadd_535 (Add)                   (None, 128, 128, 256 0           activation_752[0][0]             \n                                                                 activation_750[0][0]             \n__________________________________________________________________________________________________\nconv2d_1058 (Conv2D)            (None, 128, 128, 256 590080      add_535[0][0]                    \n__________________________________________________________________________________________________\nactivation_753 (Activation)     (None, 128, 128, 256 0           conv2d_1058[0][0]                \n__________________________________________________________________________________________________\nadd_536 (Add)                   (None, 128, 128, 256 0           activation_753[0][0]             \n                                                                 conv2d_1052[0][0]                \n__________________________________________________________________________________________________\nup_sampling2d_106 (UpSampling2D (None, 256, 256, 256 0           add_536[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1059 (Conv2D)            (None, 256, 256, 64) 8256        add_509[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1060 (Conv2D)            (None, 256, 256, 64) 16448       up_sampling2d_106[0][0]          \n__________________________________________________________________________________________________\nadd_537 (Add)                   (None, 256, 256, 64) 0           conv2d_1059[0][0]                \n                                                                 conv2d_1060[0][0]                \n__________________________________________________________________________________________________\nactivation_754 (Activation)     (None, 256, 256, 64) 0           add_537[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1061 (Conv2D)            (None, 256, 256, 1)  65          activation_754[0][0]             \n__________________________________________________________________________________________________\nactivation_755 (Activation)     (None, 256, 256, 1)  0           conv2d_1061[0][0]                \n__________________________________________________________________________________________________\nmultiply_34 (Multiply)          (None, 256, 256, 128 0           add_509[0][0]                    \n                                                                 activation_755[0][0]             \n__________________________________________________________________________________________________\nlambda_142 (Lambda)             (None, 256, 256, 384 0           up_sampling2d_106[0][0]          \n                                                                 multiply_34[0][0]                \n__________________________________________________________________________________________________\nconv2d_1062 (Conv2D)            (None, 256, 256, 128 49280       lambda_142[0][0]                 \n__________________________________________________________________________________________________\nconv2d_1063 (Conv2D)            (None, 256, 256, 128 147584      conv2d_1062[0][0]                \n__________________________________________________________________________________________________\nactivation_756 (Activation)     (None, 256, 256, 128 0           conv2d_1063[0][0]                \n__________________________________________________________________________________________________\nadd_538 (Add)                   (None, 256, 256, 128 0           activation_756[0][0]             \n                                                                 conv2d_1062[0][0]                \n__________________________________________________________________________________________________\nconv2d_1064 (Conv2D)            (None, 256, 256, 128 147584      add_538[0][0]                    \n__________________________________________________________________________________________________\nactivation_757 (Activation)     (None, 256, 256, 128 0           conv2d_1064[0][0]                \n__________________________________________________________________________________________________\nadd_539 (Add)                   (None, 256, 256, 128 0           activation_757[0][0]             \n                                                                 conv2d_1062[0][0]                \n__________________________________________________________________________________________________\nconv2d_1065 (Conv2D)            (None, 256, 256, 128 147584      add_539[0][0]                    \n__________________________________________________________________________________________________\nactivation_758 (Activation)     (None, 256, 256, 128 0           conv2d_1065[0][0]                \n__________________________________________________________________________________________________\nconv2d_1066 (Conv2D)            (None, 256, 256, 128 147584      activation_758[0][0]             \n__________________________________________________________________________________________________\nactivation_759 (Activation)     (None, 256, 256, 128 0           conv2d_1066[0][0]                \n__________________________________________________________________________________________________\nadd_540 (Add)                   (None, 256, 256, 128 0           activation_759[0][0]             \n                                                                 activation_758[0][0]             \n__________________________________________________________________________________________________\nconv2d_1067 (Conv2D)            (None, 256, 256, 128 147584      add_540[0][0]                    \n__________________________________________________________________________________________________\nactivation_760 (Activation)     (None, 256, 256, 128 0           conv2d_1067[0][0]                \n__________________________________________________________________________________________________\nadd_541 (Add)                   (None, 256, 256, 128 0           activation_760[0][0]             \n                                                                 activation_758[0][0]             \n__________________________________________________________________________________________________\nconv2d_1068 (Conv2D)            (None, 256, 256, 128 147584      add_541[0][0]                    \n__________________________________________________________________________________________________\nactivation_761 (Activation)     (None, 256, 256, 128 0           conv2d_1068[0][0]                \n__________________________________________________________________________________________________\nadd_542 (Add)                   (None, 256, 256, 128 0           activation_761[0][0]             \n                                                                 conv2d_1062[0][0]                \n__________________________________________________________________________________________________\nup_sampling2d_107 (UpSampling2D (None, 512, 512, 128 0           add_542[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1069 (Conv2D)            (None, 512, 512, 32) 2080        add_504[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1070 (Conv2D)            (None, 512, 512, 32) 4128        up_sampling2d_107[0][0]          \n__________________________________________________________________________________________________\nadd_543 (Add)                   (None, 512, 512, 32) 0           conv2d_1069[0][0]                \n                                                                 conv2d_1070[0][0]                \n__________________________________________________________________________________________________\nactivation_762 (Activation)     (None, 512, 512, 32) 0           add_543[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1071 (Conv2D)            (None, 512, 512, 1)  33          activation_762[0][0]             \n__________________________________________________________________________________________________\nactivation_763 (Activation)     (None, 512, 512, 1)  0           conv2d_1071[0][0]                \n__________________________________________________________________________________________________\nmultiply_35 (Multiply)          (None, 512, 512, 64) 0           add_504[0][0]                    \n                                                                 activation_763[0][0]             \n__________________________________________________________________________________________________\nlambda_143 (Lambda)             (None, 512, 512, 192 0           up_sampling2d_107[0][0]          \n                                                                 multiply_35[0][0]                \n__________________________________________________________________________________________________\nconv2d_1072 (Conv2D)            (None, 512, 512, 64) 12352       lambda_143[0][0]                 \n__________________________________________________________________________________________________\nconv2d_1073 (Conv2D)            (None, 512, 512, 64) 36928       conv2d_1072[0][0]                \n__________________________________________________________________________________________________\nactivation_764 (Activation)     (None, 512, 512, 64) 0           conv2d_1073[0][0]                \n__________________________________________________________________________________________________\nadd_544 (Add)                   (None, 512, 512, 64) 0           activation_764[0][0]             \n                                                                 conv2d_1072[0][0]                \n__________________________________________________________________________________________________\nconv2d_1074 (Conv2D)            (None, 512, 512, 64) 36928       add_544[0][0]                    \n__________________________________________________________________________________________________\nactivation_765 (Activation)     (None, 512, 512, 64) 0           conv2d_1074[0][0]                \n__________________________________________________________________________________________________\nadd_545 (Add)                   (None, 512, 512, 64) 0           activation_765[0][0]             \n                                                                 conv2d_1072[0][0]                \n__________________________________________________________________________________________________\nconv2d_1075 (Conv2D)            (None, 512, 512, 64) 36928       add_545[0][0]                    \n__________________________________________________________________________________________________\nactivation_766 (Activation)     (None, 512, 512, 64) 0           conv2d_1075[0][0]                \n__________________________________________________________________________________________________\nconv2d_1076 (Conv2D)            (None, 512, 512, 64) 36928       activation_766[0][0]             \n__________________________________________________________________________________________________\nactivation_767 (Activation)     (None, 512, 512, 64) 0           conv2d_1076[0][0]                \n__________________________________________________________________________________________________\nadd_546 (Add)                   (None, 512, 512, 64) 0           activation_767[0][0]             \n                                                                 activation_766[0][0]             \n__________________________________________________________________________________________________\nconv2d_1077 (Conv2D)            (None, 512, 512, 64) 36928       add_546[0][0]                    \n__________________________________________________________________________________________________\nactivation_768 (Activation)     (None, 512, 512, 64) 0           conv2d_1077[0][0]                \n__________________________________________________________________________________________________\nadd_547 (Add)                   (None, 512, 512, 64) 0           activation_768[0][0]             \n                                                                 activation_766[0][0]             \n__________________________________________________________________________________________________\nconv2d_1078 (Conv2D)            (None, 512, 512, 64) 36928       add_547[0][0]                    \n__________________________________________________________________________________________________\nactivation_769 (Activation)     (None, 512, 512, 64) 0           conv2d_1078[0][0]                \n__________________________________________________________________________________________________\nadd_548 (Add)                   (None, 512, 512, 64) 0           activation_769[0][0]             \n                                                                 conv2d_1072[0][0]                \n__________________________________________________________________________________________________\nconv2d_1079 (Conv2D)            (None, 512, 512, 1)  65          add_548[0][0]                    \n__________________________________________________________________________________________________\nactivation_770 (Activation)     (None, 512, 512, 1)  0           conv2d_1079[0][0]                \n==================================================================================================\nTotal params: 96,509,733\nTrainable params: 96,509,733\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit_generator(train_data,\n                              epochs=32,\n                              steps_per_epoch=300,\n                              validation_steps=100,\n                              validation_data=valid_data,\n                              callbacks=[model_checkpoint1 , ReduceLROnPlateau(monitor='iou_coeff', factor=0.1, patience=4)])\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T14:20:20.100997Z","iopub.execute_input":"2021-07-26T14:20:20.101271Z","iopub.status.idle":"2021-07-26T15:56:42.569746Z","shell.execute_reply.started":"2021-07-26T14:20:20.101226Z","shell.execute_reply":"2021-07-26T15:56:42.567022Z"},"trusted":true},"execution_count":196,"outputs":[{"name":"stdout","text":"Found 600 images belonging to 1 classes.\nFound 600 images belonging to 1 classes.\nEpoch 1/32\n300/300 [==============================] - ETA: 0s - loss: 2.9558 - acc: 0.9793 - recall: 0.1990 - precision: 0.1767 - iou_coeff: 0.0838 - dice_loss: 0.8608Found 200 images belonging to 1 classes.\nFound 200 images belonging to 1 classes.\n300/300 [==============================] - 220s 715ms/step - loss: 2.9550 - acc: 0.9793 - recall: 0.1994 - precision: 0.1772 - iou_coeff: 0.0840 - dice_loss: 0.8605 - val_loss: 1.9256 - val_acc: 0.9891 - val_recall: 0.5553 - val_precision: 0.6074 - val_iou_coeff: 0.3913 - val_dice_loss: 0.4508\n\nEpoch 00001: val_iou_coeff improved from inf to 0.39125, saving model to Res2Net.hdf5\nEpoch 2/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.9739 - acc: 0.9870 - recall: 0.5870 - precision: 0.5745 - iou_coeff: 0.3649 - dice_loss: 0.4845 - val_loss: 1.9853 - val_acc: 0.9836 - val_recall: 0.7130 - val_precision: 0.4460 - val_iou_coeff: 0.3689 - val_dice_loss: 0.4754\n\nEpoch 00002: val_iou_coeff improved from 0.39125 to 0.36894, saving model to Res2Net.hdf5\nEpoch 3/32\n300/300 [==============================] - 213s 712ms/step - loss: 1.6287 - acc: 0.9895 - recall: 0.6959 - precision: 0.6537 - iou_coeff: 0.4736 - dice_loss: 0.3713 - val_loss: 1.7645 - val_acc: 0.9907 - val_recall: 0.5776 - val_precision: 0.6923 - val_iou_coeff: 0.4519 - val_dice_loss: 0.3957\n\nEpoch 00003: val_iou_coeff did not improve from 0.36894\nEpoch 4/32\n300/300 [==============================] - 214s 713ms/step - loss: 1.6146 - acc: 0.9908 - recall: 0.6581 - precision: 0.6863 - iou_coeff: 0.4812 - dice_loss: 0.3734 - val_loss: 1.9524 - val_acc: 0.9917 - val_recall: 0.4501 - val_precision: 0.8154 - val_iou_coeff: 0.3923 - val_dice_loss: 0.4644\n\nEpoch 00004: val_iou_coeff did not improve from 0.36894\nEpoch 5/32\n300/300 [==============================] - 214s 712ms/step - loss: 1.6021 - acc: 0.9914 - recall: 0.6612 - precision: 0.6704 - iou_coeff: 0.4826 - dice_loss: 0.3705 - val_loss: 1.6360 - val_acc: 0.9897 - val_recall: 0.6853 - val_precision: 0.6172 - val_iou_coeff: 0.4789 - val_dice_loss: 0.3680\n\nEpoch 00005: val_iou_coeff did not improve from 0.36894\nEpoch 6/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.3949 - acc: 0.9918 - recall: 0.7581 - precision: 0.6829 - iou_coeff: 0.5423 - dice_loss: 0.3084 - val_loss: 1.5208 - val_acc: 0.9910 - val_recall: 0.7052 - val_precision: 0.6651 - val_iou_coeff: 0.5126 - val_dice_loss: 0.3378\n\nEpoch 00006: val_iou_coeff did not improve from 0.36894\nEpoch 7/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.2519 - acc: 0.9929 - recall: 0.7732 - precision: 0.7307 - iou_coeff: 0.5900 - dice_loss: 0.2686 - val_loss: 1.4256 - val_acc: 0.9925 - val_recall: 0.6880 - val_precision: 0.7315 - val_iou_coeff: 0.5450 - val_dice_loss: 0.3136\n\nEpoch 00007: val_iou_coeff did not improve from 0.36894\nEpoch 8/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.3035 - acc: 0.9928 - recall: 0.7436 - precision: 0.7374 - iou_coeff: 0.5746 - dice_loss: 0.2840 - val_loss: 1.3258 - val_acc: 0.9926 - val_recall: 0.7477 - val_precision: 0.7202 - val_iou_coeff: 0.5693 - val_dice_loss: 0.2878\n\nEpoch 00008: val_iou_coeff did not improve from 0.36894\nEpoch 9/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.2174 - acc: 0.9932 - recall: 0.7763 - precision: 0.7320 - iou_coeff: 0.6024 - dice_loss: 0.2630 - val_loss: 1.4095 - val_acc: 0.9931 - val_recall: 0.6616 - val_precision: 0.7966 - val_iou_coeff: 0.5556 - val_dice_loss: 0.3017\n\nEpoch 00009: val_iou_coeff did not improve from 0.36894\nEpoch 10/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.1359 - acc: 0.9940 - recall: 0.7837 - precision: 0.7780 - iou_coeff: 0.6293 - dice_loss: 0.2367 - val_loss: 1.4137 - val_acc: 0.9926 - val_recall: 0.7027 - val_precision: 0.7414 - val_iou_coeff: 0.5470 - val_dice_loss: 0.3117\n\nEpoch 00010: val_iou_coeff did not improve from 0.36894\nEpoch 11/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.1161 - acc: 0.9940 - recall: 0.8036 - precision: 0.7632 - iou_coeff: 0.6327 - dice_loss: 0.2336 - val_loss: 1.3302 - val_acc: 0.9927 - val_recall: 0.7265 - val_precision: 0.7345 - val_iou_coeff: 0.5710 - val_dice_loss: 0.2893\n\nEpoch 00011: val_iou_coeff did not improve from 0.36894\nEpoch 12/32\n300/300 [==============================] - 213s 712ms/step - loss: 1.1367 - acc: 0.9940 - recall: 0.7913 - precision: 0.7611 - iou_coeff: 0.6259 - dice_loss: 0.2434 - val_loss: 1.4070 - val_acc: 0.9924 - val_recall: 0.7032 - val_precision: 0.7367 - val_iou_coeff: 0.5481 - val_dice_loss: 0.3094\n\nEpoch 00012: val_iou_coeff did not improve from 0.36894\nEpoch 13/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.1196 - acc: 0.9938 - recall: 0.8031 - precision: 0.7603 - iou_coeff: 0.6320 - dice_loss: 0.2355 - val_loss: 1.3318 - val_acc: 0.9925 - val_recall: 0.7342 - val_precision: 0.7236 - val_iou_coeff: 0.5695 - val_dice_loss: 0.2891\n\nEpoch 00013: val_iou_coeff did not improve from 0.36894\nEpoch 14/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.2026 - acc: 0.9932 - recall: 0.7743 - precision: 0.7343 - iou_coeff: 0.6071 - dice_loss: 0.2609 - val_loss: 1.3926 - val_acc: 0.9924 - val_recall: 0.7191 - val_precision: 0.7131 - val_iou_coeff: 0.5501 - val_dice_loss: 0.3070\n\nEpoch 00014: val_iou_coeff did not improve from 0.36894\nEpoch 15/32\n300/300 [==============================] - 213s 712ms/step - loss: 1.1458 - acc: 0.9938 - recall: 0.7821 - precision: 0.7743 - iou_coeff: 0.6262 - dice_loss: 0.2411 - val_loss: 1.3732 - val_acc: 0.9924 - val_recall: 0.7248 - val_precision: 0.7271 - val_iou_coeff: 0.5562 - val_dice_loss: 0.3043\n\nEpoch 00015: val_iou_coeff did not improve from 0.36894\nEpoch 16/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.1374 - acc: 0.9939 - recall: 0.7895 - precision: 0.7678 - iou_coeff: 0.6273 - dice_loss: 0.2385 - val_loss: 1.3287 - val_acc: 0.9927 - val_recall: 0.7300 - val_precision: 0.7424 - val_iou_coeff: 0.5715 - val_dice_loss: 0.2875\n\nEpoch 00016: val_iou_coeff did not improve from 0.36894\nEpoch 17/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.1639 - acc: 0.9935 - recall: 0.7956 - precision: 0.7448 - iou_coeff: 0.6175 - dice_loss: 0.2484 - val_loss: 1.3230 - val_acc: 0.9930 - val_recall: 0.7313 - val_precision: 0.7402 - val_iou_coeff: 0.5717 - val_dice_loss: 0.2871\n\nEpoch 00017: val_iou_coeff did not improve from 0.36894\nEpoch 18/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.1530 - acc: 0.9936 - recall: 0.7897 - precision: 0.7586 - iou_coeff: 0.6226 - dice_loss: 0.2427 - val_loss: 1.3652 - val_acc: 0.9925 - val_recall: 0.7130 - val_precision: 0.7322 - val_iou_coeff: 0.5603 - val_dice_loss: 0.3004\n\nEpoch 00018: val_iou_coeff did not improve from 0.36894\nEpoch 19/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.1344 - acc: 0.9939 - recall: 0.7887 - precision: 0.7663 - iou_coeff: 0.6283 - dice_loss: 0.2391 - val_loss: 1.4039 - val_acc: 0.9926 - val_recall: 0.7094 - val_precision: 0.7249 - val_iou_coeff: 0.5476 - val_dice_loss: 0.3076\n\nEpoch 00019: val_iou_coeff did not improve from 0.36894\nEpoch 20/32\n300/300 [==============================] - 213s 712ms/step - loss: 1.1463 - acc: 0.9937 - recall: 0.7923 - precision: 0.7643 - iou_coeff: 0.6246 - dice_loss: 0.2432 - val_loss: 1.3701 - val_acc: 0.9924 - val_recall: 0.7207 - val_precision: 0.7408 - val_iou_coeff: 0.5589 - val_dice_loss: 0.2949\n\nEpoch 00020: val_iou_coeff did not improve from 0.36894\nEpoch 21/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.1514 - acc: 0.9938 - recall: 0.7981 - precision: 0.7461 - iou_coeff: 0.6204 - dice_loss: 0.2464 - val_loss: 1.3206 - val_acc: 0.9929 - val_recall: 0.7279 - val_precision: 0.7364 - val_iou_coeff: 0.5735 - val_dice_loss: 0.2861\n\nEpoch 00021: val_iou_coeff did not improve from 0.36894\nEpoch 22/32\n300/300 [==============================] - 213s 712ms/step - loss: 1.1847 - acc: 0.9937 - recall: 0.7748 - precision: 0.7593 - iou_coeff: 0.6125 - dice_loss: 0.2526 - val_loss: 1.3434 - val_acc: 0.9927 - val_recall: 0.7218 - val_precision: 0.7294 - val_iou_coeff: 0.5676 - val_dice_loss: 0.2918\n\nEpoch 00022: val_iou_coeff did not improve from 0.36894\nEpoch 23/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.1659 - acc: 0.9936 - recall: 0.7924 - precision: 0.7491 - iou_coeff: 0.6165 - dice_loss: 0.2481 - val_loss: 1.4023 - val_acc: 0.9924 - val_recall: 0.7148 - val_precision: 0.7353 - val_iou_coeff: 0.5463 - val_dice_loss: 0.3075\n\nEpoch 00023: val_iou_coeff did not improve from 0.36894\nEpoch 24/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.1601 - acc: 0.9937 - recall: 0.7813 - precision: 0.7651 - iou_coeff: 0.6205 - dice_loss: 0.2456 - val_loss: 1.2983 - val_acc: 0.9930 - val_recall: 0.7463 - val_precision: 0.7357 - val_iou_coeff: 0.5794 - val_dice_loss: 0.2783\n\nEpoch 00024: val_iou_coeff did not improve from 0.36894\nEpoch 25/32\n300/300 [==============================] - 213s 711ms/step - loss: 1.1470 - acc: 0.9937 - recall: 0.8006 - precision: 0.7482 - iou_coeff: 0.6227 - dice_loss: 0.2432 - val_loss: 1.3852 - val_acc: 0.9924 - val_recall: 0.7012 - val_precision: 0.7298 - val_iou_coeff: 0.5556 - val_dice_loss: 0.3044\n\nEpoch 00025: val_iou_coeff did not improve from 0.36894\nEpoch 26/32\n300/300 [==============================] - 213s 712ms/step - loss: 1.1039 - acc: 0.9941 - recall: 0.7993 - precision: 0.7741 - iou_coeff: 0.6376 - dice_loss: 0.2304 - val_loss: 1.3440 - val_acc: 0.9927 - val_recall: 0.7293 - val_precision: 0.7458 - val_iou_coeff: 0.5659 - val_dice_loss: 0.2903\n\nEpoch 00026: val_iou_coeff did not improve from 0.36894\nEpoch 27/32\n300/300 [==============================] - 214s 712ms/step - loss: 1.1623 - acc: 0.9937 - recall: 0.7884 - precision: 0.7481 - iou_coeff: 0.6183 - dice_loss: 0.2480 - val_loss: 1.3547 - val_acc: 0.9929 - val_recall: 0.7228 - val_precision: 0.7169 - val_iou_coeff: 0.5610 - val_dice_loss: 0.3034\n\nEpoch 00027: val_iou_coeff did not improve from 0.36894\nEpoch 28/32\n 11/300 [>.............................] - ETA: 3:06 - loss: 1.5896 - acc: 0.9906 - recall: 0.7499 - precision: 0.5994 - iou_coeff: 0.4733 - dice_loss: 0.3737","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-196-9930c036bd1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                               callbacks=[model_checkpoint1 , ReduceLROnPlateau(monitor='iou_coeff', factor=0.1, patience=4)])\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path = '../input/testdata/Test'\ntest_image_folder =\"images\"\nTest_path = test_path + '/' + 'test_image_folder'\ntest_label_folder =\"label\"\n\n\ndp = data_preprocess(train_path=train_path,image_folder=image_folder,label_folder=label_folder,\n                     valid_path=valid_path,valid_image_folder=valid_image_folder,valid_label_folder=valid_label_folder,\n                     flag_multi_class=flag_multi_class,\n                     num_classes=num_classes , test_path = Test_path , save_path = './' )\n\ntest_data = dp.testGenerator()\n\nimport os\n  \n# Directory\ndirectory = \"RESULT_R2NET\"\n  \n# Parent Directory path\nparent_dir = \"./\"\n  \n# Path\npath = os.path.join(parent_dir, directory)\nos.mkdir(path)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-26T15:56:42.570969Z","iopub.status.idle":"2021-07-26T15:56:42.571523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef read_image(path):\n    x = cv2.imread(path, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (512, 512))\n    x = x/255.0\n    return x\n\ndef read_mask(path):\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, ( 512 , 512))\n    x = np.expand_dims(x, axis=-1)\n    return x\n\ndef mask_parse(mask):\n    mask = np.squeeze(mask)\n    mask = [mask, mask, mask]\n    mask = np.transpose(mask, (1, 2, 0))\n    return mask\n\n\n\n\ndef tf_parse(imagepath , maskpath):\n  def _parse(imagepath , maskpath):\n    x = read_image(imagepath)\n    y = read_mask(maskpath)\n\n    return x , y\n\n  x , y = tf.numpy_function(_parse , [imagepath , maskpath] , [tf.float64 , tf.float64] )\n  x.set_shape([512 , 512 , 3])\n  y.set_shape([512, 512, 1])\n\n  return x , y \n\n\ndef tf_dataset( imagepath , maskpath , batch = 2):\n  dataset = tf.data.Dataset.from_tensor_slices((imagepath , maskpath))\n  dataset = dataset.map(tf_parse)\n  dataset = dataset.batch(batch)\n  dataset = dataset.repeat()\n  return dataset\n\n\nif __name__ == \"__main__\":\n    ## Dataset\n    \n    batch_size = 8\n    #(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(\"/content/drive/MyDrive/Test\")\n    test_x = os.listdir(os.path.join(test_path ,test_image_folder ))\n    test_y = os.listdir(os.path.join(test_path ,test_label_folder ))\n    \n    test_dataset = tf_dataset(test_x, test_y, batch=batch_size)\n\n    test_steps = (len(test_x)//batch_size)\n    if len(test_x) % batch_size != 0:\n        test_steps += 1\n\n    #with CustomObjectScope({'iou': iou}):\n    #    model = tf.keras.models.load_model(\"/content/drive/model.h5\")\n\n    #model.evaluate(test_dataset, steps=test_steps)\n\n    for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n        x = read_image(x)\n        y = read_mask(y)\n        y_pred = model.predict(np.expand_dims(x, axis=0))[0] > 0.5\n        h, w, _ = x.shape\n        white_line = np.ones((h, 10, 3)) * 255.0\n\n        all_images = [\n            x * 255.0, white_line,\n            mask_parse(y), white_line,\n            mask_parse(y_pred) * 255.0\n        ]\n        image = np.concatenate(all_images, axis=1)\n        \n        cv2.imwrite(f\"./RESULT_DenseNet210WithDropout/{i}.png\", image)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T15:56:42.572982Z","iopub.status.idle":"2021-07-26T15:56:42.573562Z"},"trusted":true},"execution_count":null,"outputs":[]}]}